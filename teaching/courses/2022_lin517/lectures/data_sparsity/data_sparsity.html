<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.233">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Josef Fruehwald">
<meta name="dcterms.date" content="2022-08-31">

<title>Lin517: Natural Language Processing - Data Sparsity</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../lectures/data_processing/index.html" rel="next">
<link href="../../lectures/what_is_nlp/index.html" rel="prev">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/quarto-contrib/fontawesome6-0.1.0/all.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/fontawesome6-0.1.0/latex-fontsize.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>
<link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Atkinson+Hyperlegible">

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">Data Sparsity</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../">Lin517: Natural Language Processing</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Resources</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../resources/reading/index.html" class="sidebar-item-text sidebar-link">Reading a technical paper</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../resources/notation/index.html" class="sidebar-item-text sidebar-link">Mathematical notation</a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">Lecture Notes</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">Intro</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth2 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/what_is_nlp/index.html" class="sidebar-item-text sidebar-link">What is NLP?</a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">Data Sparsity and Processing</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth2 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/data_sparsity/data_sparsity.html" class="sidebar-item-text sidebar-link active">Data Sparsity</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/data_processing/index.html" class="sidebar-item-text sidebar-link">Data processing</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/data_processing/addendum.html" class="sidebar-item-text sidebar-link">Data processing – addendum</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/lem_stem/index.html" class="sidebar-item-text sidebar-link">Lemmatizing and stemming</a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">ngrams</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth2 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/ngram/index.html" class="sidebar-item-text sidebar-link">ngram Language Models</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/ngram/01-ngram-eval.html" class="sidebar-item-text sidebar-link">ngrams - Perplexity</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/ngram/02_smoothing.html" class="sidebar-item-text sidebar-link">ngram - Smoothing</a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../lectures/word_vectors/index.html" class="sidebar-item-text sidebar-link">Word Vectors</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth2 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/word_vectors/01_concept.html" class="sidebar-item-text sidebar-link">Word Vectors - Concepts</a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">Models</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth2 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/evaluation/index.html" class="sidebar-item-text sidebar-link">Evaluating models</a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true">python sessions</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../python_sessions/00_session1.html" class="sidebar-item-text sidebar-link">Starting Python</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../python_sessions/01_session2.html" class="sidebar-item-text sidebar-link">Lists and Dictionaries</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../python_sessions/02_session3.html" class="sidebar-item-text sidebar-link">Loops Etc.</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../python_sessions/03_session4.html" class="sidebar-item-text sidebar-link">Comprehensions and Useful Things</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../python_sessions/04_session5.html" class="sidebar-item-text sidebar-link">Making and Counting Bigrams</a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#bug-catching" id="toc-bug-catching" class="nav-link active" data-scroll-target="#bug-catching">Bug Catching</a>
  <ul class="collapse">
  <li><a href="#making-predictions" id="toc-making-predictions" class="nav-link" data-scroll-target="#making-predictions">Making Predictions</a></li>
  <li><a href="#a-wild-fa-bug-appeared" id="toc-a-wild-fa-bug-appeared" class="nav-link" data-scroll-target="#a-wild-fa-bug-appeared">A wild <span class="bug6"><i class="fa-solid fa-bug" aria-hidden="true"></i></span> appeared!</a></li>
  </ul></li>
  <li><a href="#youd-need-fa-infinity" id="toc-youd-need-fa-infinity" class="nav-link" data-scroll-target="#youd-need-fa-infinity">You’d need <i class="fa-solid fa-infinity" aria-hidden="true"></i></a>
  <ul class="collapse">
  <li><a href="#aint-no-corpus-large-enough" id="toc-aint-no-corpus-large-enough" class="nav-link" data-scroll-target="#aint-no-corpus-large-enough">🎵 Ain’t no corpus large enough 🎵</a></li>
  <li><a href="#an-aside" id="toc-an-aside" class="nav-link" data-scroll-target="#an-aside">An aside</a></li>
  <li><a href="#it-gets-worse" id="toc-it-gets-worse" class="nav-link" data-scroll-target="#it-gets-worse">It gets worse</a></li>
  </ul></li>
  <li><a href="#some-notes-on-power-laws" id="toc-some-notes-on-power-laws" class="nav-link" data-scroll-target="#some-notes-on-power-laws">Some Notes on Power Laws</a></li>
  <li><a href="#extra" id="toc-extra" class="nav-link" data-scroll-target="#extra">Extra</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block">Data Sparsity</h1>
  <div class="quarto-categories">
    <div class="quarto-category">data</div>
  </div>
  </div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Josef Fruehwald </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">August 31, 2022</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<section id="bug-catching" class="level2">
<h2 class="anchored" data-anchor-id="bug-catching">Bug Catching</h2>
<p>Let’s say we’re biologists, working in a rain forest, and put out a bug net to survey the biodiversity of the forest. We catch 10 bugs, and each species is a different color:</p>
<p>[<span class="bug1"><i class="fa-solid fa-bug" aria-hidden="true"></i><span class="math inline">\(_1\)</span></span>, <span class="bug1"><i class="fa-solid fa-bug" aria-hidden="true"></i><span class="math inline">\(_2\)</span></span>, <span class="bug1"><i class="fa-solid fa-bug" aria-hidden="true"></i><span class="math inline">\(_3\)</span></span>, <span class="bug1"><i class="fa-solid fa-bug" aria-hidden="true"></i><span class="math inline">\(_4\)</span></span>, <span class="bug1"><i class="fa-solid fa-bug" aria-hidden="true"></i><span class="math inline">\(_5\)</span></span>, <span class="bug2"><i class="fa-solid fa-bug" aria-hidden="true"></i><span class="math inline">\(_6\)</span></span>, <span class="bug2"><i class="fa-solid fa-bug" aria-hidden="true"></i><span class="math inline">\(_7\)</span></span>, <span class="bug3"><i class="fa-solid fa-bug" aria-hidden="true"></i><span class="math inline">\(_8\)</span></span>, <span class="bug4"><i class="fa-solid fa-bug" aria-hidden="true"></i><span class="math inline">\(_9\)</span></span>, <span class="bug5"><i class="fa-solid fa-bug" aria-hidden="true"></i><span class="math inline">\(_{10}\)</span></span>]</p>
<p>We have 10 bugs in total, so we’ll say <span class="math inline">\(N=10\)</span>. This is our “token count.” We’ll use the <span class="math inline">\(i\)</span> subscript to refer to each individual bug (or token).</p>
<p>If we made a table of each bug species, it would look like:</p>
<table class="table">
<thead>
<tr class="header">
<th>species</th>
<th>index <span class="math inline">\(j\)</span></th>
<th>count</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="bug1"><i class="fa-solid fa-bug" aria-hidden="true"></i></span></td>
<td>1</td>
<td>5</td>
</tr>
<tr class="even">
<td><span class="bug2"><i class="fa-solid fa-bug" aria-hidden="true"></i></span></td>
<td>2</td>
<td>2</td>
</tr>
<tr class="odd">
<td><span class="bug3"><i class="fa-solid fa-bug" aria-hidden="true"></i></span></td>
<td>3</td>
<td>1</td>
</tr>
<tr class="even">
<td><span class="bug4"><i class="fa-solid fa-bug" aria-hidden="true"></i></span></td>
<td>4</td>
<td>1</td>
</tr>
<tr class="odd">
<td><span class="bug5"><i class="fa-solid fa-bug" aria-hidden="true"></i></span></td>
<td>5</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>Let’s use <span class="math inline">\(M\)</span> to represent the total number of species, so <span class="math inline">\(M=5\)</span> here. This is our <em>type</em> count, and we’ll the subscript <span class="math inline">\(j\)</span> to represent the index of specific <em>types</em>.</p>
<p>We can mathematically represent the count of each species like so.</p>
<p><span class="math display">\[
c_j = C(\class{fa fa-bug}{}_j)
\]</span></p>
<p>Here, the function <span class="math inline">\(C()\)</span> takes a specific species representation <span class="math inline">\(\class{fa fa-bug}{}_j\)</span> as input, and returns the specific count <span class="math inline">\(c_j\)</span> for how many times that species showed up in our net. So when <span class="math inline">\(j = {\color{#785EF0}{1}}\)</span>, <span class="math inline">\(\color{#785EF0}{c_1}=5\)</span>, and when <span class="math inline">\(j = {\color{#FFB000}{4}}\)</span>, <span class="math inline">\(\color{#FFB000}{c_4}=1\)</span>.</p>
<p>Here’s a plot, with the species id <span class="math inline">\(j\)</span> on the x-axis, and the number of times that species appeared in the net <span class="math inline">\(c_j\)</span> on the y-axis.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="data_sparsity_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid" width="576"></p>
</div>
</div>
<section id="making-predictions" class="level3">
<h3 class="anchored" data-anchor-id="making-predictions">Making Predictions</h3>
<p>What is the probability that tomorrow, when we put the net out again, that the first bug we catch will be from species <span class="bug1"><i class="fa-solid fa-bug" aria-hidden="true"></i></span>? Usually in these cases, we’ll use past experience to predict the future. Today, of the <span class="math inline">\(N=10\)</span> bugs we caught, <span class="math inline">\(\color{#785EF0}{c_1}=5\)</span> of them were species <span class="bug1"><i class="fa-solid fa-bug" aria-hidden="true"></i></span>. We can represent this as a fraction like so:</p>
<p><span class="math display">\[
\frac{{\color{#785EF0}{\class{fa fa-bug}{}}}_1,
      {\color{#785EF0}{\class{fa fa-bug}{}}}_2,
      {\color{#785EF0}{\class{fa fa-bug}{}}}_3,
      {\color{#785EF0}{\class{fa fa-bug}{}}}_4,
      {\color{#785EF0}{\class{fa fa-bug}{}}}_5}
{{\color{#785EF0}{\class{fa fa-bug}{}}}_1,
      {\color{#785EF0}{\class{fa fa-bug}{}}}_2,
      {\color{#785EF0}{\class{fa fa-bug}{}}}_3,
      {\color{#785EF0}{\class{fa fa-bug}{}}}_4,
      {\color{#785EF0}{\class{fa fa-bug}{}}}_5,
      {\color{#DC267F}{\class{fa fa-bug}{}}}_6,
      {\color{#DC267F}{\class{fa fa-bug}{}}}_7,
      {\color{#FE6100}{\class{fa fa-bug}{}}}_8,
      {\color{#FFB000}{\class{fa fa-bug}{}}}_9,
      {\color{#4C8C05}{\class{fa fa-bug}{}}}_{10}}
\]</span></p>
<p>Or, we can simplify it a little bit. The top part (the numerator) is equal to <span class="math inline">\(\color{#785EF0}{c_1}=5\)</span>, and the bottom part (the denominator) is equal to the total number of bugs, <span class="math inline">\(N\)</span>. Simplifying then:</p>
<p><span class="math display">\[
\frac{\color{#785EF0}{c_1}}{N} = \frac{5}{10} = 0.5
\]</span></p>
<p>We’ll use this as our guesstimate of the probability that the very next bug we catch will be from species <span class="bug1"><i class="fa-solid fa-bug" aria-hidden="true"></i></span>. Let’s use the function <span class="math inline">\(\hat{P}()\)</span> to mean “our method for guessing the probability”, and <span class="math inline">\(\hat{p}\)</span> to represent the guess we came to. We could express “our guess that the first bug we catch will be <span class="bug1"><i class="fa-solid fa-bug" aria-hidden="true"></i></span>” like so.</p>
<p><span class="math display">\[
{\color{#785EF0}{\hat{p}_1}} = \hat{P}({\color{#785EF0}{\class{fa fa-bug}{}}}) = \frac{\color{#785EF0}{c_1}}{N} = \frac{5}{10} = 0.5
\]</span></p>
<p>We can then generalize our method to <em>any</em> bug like so:</p>
<p><span class="math display">\[
\hat{p}_j = \hat{P}(\class{fa fa-bug}{}_j) = \frac{c_j}{N}
\]</span></p>
</section>
<section id="a-wild-fa-bug-appeared" class="level3">
<h3 class="anchored" data-anchor-id="a-wild-fa-bug-appeared">A wild <span class="bug6"><i class="fa-solid fa-bug" aria-hidden="true"></i></span> appeared!</h3>
<p>Let’s say we set out the net again, and the first bug we catch is actually <span class="bug6"><i class="fa-solid fa-bug" aria-hidden="true"></i></span>. This is a new species of bug that wasn’t in the net the first time. Makes enough sense, the forest is very large. However, what probability <em>would</em> we have given catching this new species?</p>
<p>Well, <span class="math inline">\(\color{#35F448}{c_6} = C({\color{#35F448}{\class{fa fa-bug}{}}}) = 0\)</span>. So our estimate of the probability would have been <span class="math inline">\({\color{#35F448}{\hat{p}_6}} = \hat{P}({\color{#35F448}{\class{fa fa-bug}{}}}) = \frac{\color{#35F448}{c_6}}{N} = \frac{0}{10} = 0\)</span>.</p>
<p>Well obviously, the probability that we would catch a bug from species <span class="bug6"><i class="fa-solid fa-bug" aria-hidden="true"></i></span> <em>wasn’t</em> 0, because events with 0 probability don’t happen, and we <em>did</em> catch the bug. Admittedly, <span class="math inline">\(N=10\)</span> is a small sample to try and base a probability estimate on, so how large <em>would</em> we need the sample to be before we could make probabity estimates for all possible bug species, assuming we stick with the probability estimating function <span class="math inline">\(\hat{P}(\class{fa fa-bug}{}_j) = \frac{c_j}{N}\)</span>?</p>
</section>
</section>
<section id="youd-need-fa-infinity" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="youd-need-fa-infinity">You’d need <i class="fa-solid fa-infinity" aria-hidden="true"></i></h2>
<div class="page-columns page-full"><p>This <em>kind</em> of data problem does arise for counting species, but this is really a tortured analogy for language data.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> For example, let’s take all of the words from Chapter 1 of Mary Shelly’s Frankenstein, downloaded from <a href="https://www.gutenberg.org/ebooks/84">Project Gutenberg</a>. I’ll count how often each word occurred, and assign it a rank, with 1 being given to the word that occurred the most.</p><div class="no-row-height column-margin column-container"><li id="fn1"><p><sup>1</sup>&nbsp;For me, I used this analogy to include colorful images of bugs in the lecture notes. For <span class="citation" data-cites="good1953">Good (<a href="#ref-good1953" role="doc-biblioref">1953</a>)</span>, they had to use a tortured analogy since the methods for fixing probability estimates were still classified after being used to crack the Nazi Enigma Code in WWII.</p></li></div></div>
<div class="cell">

</div>
<div class="cell">

</div>
<div class="cell">

</div>
<p>Just to draw the parallels between the two analogies:</p>
<table class="table">
<colgroup>
<col style="width: 6%">
<col style="width: 41%">
<col style="width: 51%">
</colgroup>
<thead>
<tr class="header">
<th>variable</th>
<th>in the analogy</th>
<th>in Frankenstein Chapter 1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(N\)</span></td>
<td>The total number of bugs caught in the net. (<span class="math inline">\(N=10\)</span>)</td>
<td>The total number of words in the first chapter. (<span class="math inline">\(N=1,780\)</span>).</td>
</tr>
<tr class="even">
<td><span class="math inline">\(x_i\)</span></td>
<td>An individual bug. e.g.&nbsp;<span class="bug1"><i class="fa-solid fa-bug" aria-hidden="true"></i></span><span class="math inline">\(_1\)</span></td>
<td>An individual word token. In chapter 1, <span class="math inline">\(x_1\)</span> = “i”</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(w_j\)</span></td>
<td>A bug species. <span class="bug1"><i class="fa-solid fa-bug" aria-hidden="true"></i></span></td>
<td>A word type. The indices are frequency ordered, so for chapter 1 <span class="math inline">\(w_1\)</span> = “of”</td>
</tr>
<tr class="even">
<td><span class="math inline">\(c_j\)</span></td>
<td>The count of how many <em>individuals</em> there are of a <em>species</em>.</td>
<td>The count of how many <em>tokens</em> there are of a <em>type</em>.</td>
</tr>
</tbody>
</table>
<p>Here’s a table of the top 10 most frequent word types.</p>
<div class="cell">
<div class="cell-output-display">
<table class="table table-sm table-striped">
<thead>
<tr class="header">
<th style="text-align: left;"><span class="math inline">\(w_j\)</span></th>
<th style="text-align: right;"><span class="math inline">\(c_j\)</span></th>
<th style="text-align: right;"><span class="math inline">\(j\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">of</td>
<td style="text-align: right;">75</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="even">
<td style="text-align: left;">the</td>
<td style="text-align: right;">75</td>
<td style="text-align: right;">2</td>
</tr>
<tr class="odd">
<td style="text-align: left;">and</td>
<td style="text-align: right;">70</td>
<td style="text-align: right;">3</td>
</tr>
<tr class="even">
<td style="text-align: left;">to</td>
<td style="text-align: right;">61</td>
<td style="text-align: right;">4</td>
</tr>
<tr class="odd">
<td style="text-align: left;">a</td>
<td style="text-align: right;">52</td>
<td style="text-align: right;">5</td>
</tr>
<tr class="even">
<td style="text-align: left;">her</td>
<td style="text-align: right;">52</td>
<td style="text-align: right;">6</td>
</tr>
<tr class="odd">
<td style="text-align: left;">was</td>
<td style="text-align: right;">40</td>
<td style="text-align: right;">7</td>
</tr>
<tr class="even">
<td style="text-align: left;">my</td>
<td style="text-align: right;">33</td>
<td style="text-align: right;">8</td>
</tr>
<tr class="odd">
<td style="text-align: left;">in</td>
<td style="text-align: right;">32</td>
<td style="text-align: right;">9</td>
</tr>
<tr class="even">
<td style="text-align: left;">his</td>
<td style="text-align: right;">29</td>
<td style="text-align: right;">10</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>If we plot out <em>all</em> of the word types with the rank (<span class="math inline">\(j\)</span>) on the x-axis and the count of each word type (<span class="math inline">\(c_j\)</span>) on the y-axis, we get a pattern that if you’re not already familiar with it, you will be.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="data_sparsity_files/figure-html/unnamed-chunk-8-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>This is a “Zipfian Distribution” a.k.a. a “Pareto Distribution” a.k.a. a “Power law,” and it has a few features which make it ~problematic~ for all sorts of analyses.</p>
<p>For example, let’s come back to the issue of predicting the probability of the next word we’re going to see. Language Models are “string prediction models,” after all, and in order to get a prediction for a specific string, you need to have <em>seen</em> the string in the training data. Remember how our bug prediction method had no way of predicting that we’d see a <span class="bug6"><i class="fa-solid fa-bug" aria-hidden="true"></i></span> because it had never seen one before?</p>
<p>There are a lot of possible string types of “English” that we have not observed in Chapter 1 of Frankenstein. Good &amp; Turing proposed that you could guesstimate that the probability of seeing a never before seen “species” was about equal to the proportion of “species” you’d only seen once. With just Chapter 1, that’s a pretty high probability that there are words you haven’t seen yet.</p>
<div class="cell">
<div class="cell-output-display">
<table class="table table-sm table-striped">
<thead>
<tr class="header">
<th style="text-align: left;">seen once?</th>
<th style="text-align: right;">total</th>
<th style="text-align: right;">proportion</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">no</td>
<td style="text-align: right;">1216</td>
<td style="text-align: right;">0.683</td>
</tr>
<tr class="even">
<td style="text-align: left;">yes</td>
<td style="text-align: right;">564</td>
<td style="text-align: right;">0.317</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>So, let’s increase our sample size. Here’s the same plot of rank by count for chapters 1 through 5.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="data_sparsity_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<table class="table table-sm table-striped">
<thead>
<tr class="header">
<th style="text-align: left;">seen once?</th>
<th style="text-align: right;">total</th>
<th style="text-align: right;">proportion</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">no</td>
<td style="text-align: right;">9928</td>
<td style="text-align: right;">0.858</td>
</tr>
<tr class="even">
<td style="text-align: left;">yes</td>
<td style="text-align: right;">1649</td>
<td style="text-align: right;">0.142</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>We increased the size of the whole corpus by a factor of 10, but we’ve still got a pretty high probability of encountering an unseen word.</p>
<p>Let’s expand it out to the whole book now.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="data_sparsity_files/figure-html/unnamed-chunk-12-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<table class="table table-sm table-striped">
<thead>
<tr class="header">
<th style="text-align: left;">seen once?</th>
<th style="text-align: right;">total</th>
<th style="text-align: right;">proportion</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">no</td>
<td style="text-align: right;">72122</td>
<td style="text-align: right;">0.96</td>
</tr>
<tr class="even">
<td style="text-align: left;">yes</td>
<td style="text-align: right;">3021</td>
<td style="text-align: right;">0.04</td>
</tr>
</tbody>
</table>
</div>
</div>
<section id="aint-no-corpus-large-enough" class="level3">
<h3 class="anchored" data-anchor-id="aint-no-corpus-large-enough">🎵 Ain’t no corpus large enough 🎵</h3>
<p>As it turns out, there’s no corpus large enough to guarantee observing every possible word at least once, for a few reasons.</p>
<ol type="1">
<li>The infinite generative capacity of language! The set of all possible words is, <em>in principle</em> infinitely large.</li>
<li>These power law distributions will always have the a <em>lot</em> of tokens with a frequency of 1, and even just those tokens are going to have their probabilities poorly estimated.</li>
</ol>
<p>To illustrate this, I downloaded the 1-grams of just words beginning with <code>[Aa]</code> from the <a href="https://storage.googleapis.com/books/ngrams/books/datasetsv3.html">Google Ngrams data set</a>. This is an ngram dataset based on all of the books scanned by the Google Books project. It’s 4 columns wide, 86,618,505 rows long, and 1.8G large, and even then I think it’s a truncated version of the data set, because the fewest number of years any given word appears is exactly 40.</p>
<p>If we take just all of the words that start with <code>[Aa]</code> published in the year 2000, the most <em>common</em> frequency for a word to be is still just 1, even if it is a small proportion of all tokens.</p>
<div class="cell">
<div class="cell-output-display">
<table class="table table-sm table-striped">
<caption>Frequencies of frequencies in words starting with <code>[Aa]</code> from the year 2000 in google ngrams </caption>
<colgroup>
<col style="width: 21%">
<col style="width: 43%">
<col style="width: 35%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: right;">word frequency</th>
<th style="text-align: right;">number of types with frequency</th>
<th style="text-align: right;">proportion of all tokens</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">1</td>
<td style="text-align: right;">205141</td>
<td style="text-align: right;">4.77e-10</td>
</tr>
<tr class="even">
<td style="text-align: right;">2</td>
<td style="text-align: right;">152142</td>
<td style="text-align: right;">9.55e-10</td>
</tr>
<tr class="odd">
<td style="text-align: right;">3</td>
<td style="text-align: right;">107350</td>
<td style="text-align: right;">1.43e-09</td>
</tr>
<tr class="even">
<td style="text-align: right;">4</td>
<td style="text-align: right;">80215</td>
<td style="text-align: right;">1.91e-09</td>
</tr>
<tr class="odd">
<td style="text-align: right;">5</td>
<td style="text-align: right;">60634</td>
<td style="text-align: right;">2.39e-09</td>
</tr>
<tr class="even">
<td style="text-align: right;">6</td>
<td style="text-align: right;">47862</td>
<td style="text-align: right;">2.86e-09</td>
</tr>
</tbody>
</table>
</div>
</div>
</section>
<section id="an-aside" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="an-aside">An aside</h3>
<p>I’ll be plotting the rank vs the frequency with logarithmic axes from here on. Linear axes give equal visual space for every incremental change in the x and y values, while lograrithmic axes put more space between smaller numbers than larger numbers.</p>
<div class="cell quarto-layout-panel page-columns page-full">
<div class="quarto-layout-row quarto-layout-valign-top page-columns page-full">
<div class="cell-output-display quarto-layout-cell page-columns page-full" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="data_sparsity_files/figure-html/unnamed-chunk-16-1.png" class="img-fluid figure-img" width="480"></p>
<p></p><figcaption class="figure-caption margin-caption">rank by frequency on linear scales</figcaption><p></p>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell page-columns page-full" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="data_sparsity_files/figure-html/unnamed-chunk-16-2.png" class="img-fluid figure-img" width="480"></p>
<p></p><figcaption class="figure-caption margin-caption">rank by frequency on logarithmic scales</figcaption><p></p>
</figure>
</div>
</div>
</div>
</div>
</section>
<section id="it-gets-worse" class="level3">
<h3 class="anchored" data-anchor-id="it-gets-worse">It gets worse</h3>
<p>We can maybe get very far with our data sparsity for how often we’ll see each individual word by increasing the size of our corpus size, but 1gram word counts are rarely as far as we’ll want to go.</p>
<p>To come back to our bugs example, let’s say that bug species <span class="bug6"><i class="fa-solid fa-bug" aria-hidden="true"></i></span> actually hunts bug species <span class="bug4"><i class="fa-solid fa-bug" aria-hidden="true"></i></span>. If we just caught a <span class="bug4"><i class="fa-solid fa-bug" aria-hidden="true"></i></span> in our net, it’s a lot more likely that we’ll catch a <span class="bug6"><i class="fa-solid fa-bug" aria-hidden="true"></i></span> next, coming after the helpless <span class="bug4"><i class="fa-solid fa-bug" aria-hidden="true"></i></span> than it would be if we hadn’t just caught a <span class="bug4"><i class="fa-solid fa-bug" aria-hidden="true"></i></span>. To know what <em>exactly</em> the probability catching <span class="bug4"><i class="fa-solid fa-bug" aria-hidden="true"></i></span> and then a <span class="bug6"><i class="fa-solid fa-bug" aria-hidden="true"></i></span> is, we’d need to count up every 2 bug sequence we’ve seen.</p>
<p>Bringing this back to words, 2 word sequences are called “bigrams” and 3 word sequences are called “trigrams,” and they are <em>also</em> distributed according to a Power Law, and each larger string of words has a worse data sparsity one than the one before. But each larger string of words means more context, which makes for better predictions.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="data_sparsity_files/figure-html/unnamed-chunk-17-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
</section>
<section id="some-notes-on-power-laws" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="some-notes-on-power-laws">Some Notes on Power Laws</h2>
<p>The power law distribution is pervasive in linguistic data, in almost every domain where we might count how often something happens or is observed. This is absolutely a fact that must be taken into account when we develop our theories or build our models. Some people also think it is an important fact to be explained about language, but I’m deeply skeptical.</p>
<p>A <em>lot</em> of things follow power law distributions. The general property of these distributions is that the second most frequent thing will have a frequency about as half as the most frequent thing, the third most frequent thing will have a frequency about a third of the most frequent thing, etc. We could put that mathematically as:</p>
<p><span class="math display">\[
c_j = \frac{c_1}{j}
\]</span></p>
<div class="page-columns page-full"><p>For example, here’s the log-log plot of baby name rank by baby name frequency in the US between 1880 and 2017.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p><div class="no-row-height column-margin column-container"><li id="fn2"><p><sup>2</sup>&nbsp;Data from the <code>babynames</code> R package, which in turn got the data from the Social Security Administration.</p></li></div></div>
<div class="cell page-columns page-full">
<div class="cell-output-display page-columns page-full">
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="data_sparsity_files/figure-html/unnamed-chunk-18-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption margin-caption">rank by frequency of baby names</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>The log-log plot isn’t perfectly straight (it’s common enough for data like this to have two “regimes”).</p>
<p>Here’s the number of ratings each movie on IMDB has received.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="data_sparsity_files/figure-html/unnamed-chunk-19-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>If we break down the movies by their genre, we get the same kind of result.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="data_sparsity_files/figure-html/unnamed-chunk-20-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Other things that have been shown to exhibit power law distributions <span class="citation" data-cites="newman2005 jiang2011">(<a href="#ref-newman2005" role="doc-biblioref">Newman 2005</a>; <a href="#ref-jiang2011" role="doc-biblioref">Jiang and Jia 2011</a>)</span> are</p>
<ul>
<li>US city populations</li>
<li>number of citations academic papers get</li>
<li>website traffic</li>
<li>number of copies books sell</li>
<li>earthquake magnitudes</li>
</ul>
<p>These are all possibly examples of “preferential attachment”, but we can also create an example that doesn’t involve preferential attachment, and still wind up with a power-law. Let’s take the first 12 words from Frankenstein:</p>

<table>
<tbody><tr>
<td><code>"to"</code></td><td><code>"mrs"</code></td><td><code>"saville"</code></td><td><code>"england"</code></td><td><code>"st"</code></td><td><code>"petersburgh"</code></td><td><code>"dec"</code></td><td><code>"11th"</code></td><td><code>"17"</code></td><td><code>"you"</code></td><td><code>"will"</code></td><td><code>"rejoice"</code></td>

</tr>
</tbody></table>
<p>Now, let’s paste them all together into one long string with spaces.</p>

<table>
<tbody><tr>
<td><code>"to mrs saville england st petersburgh dec 11th 17 you will rejoice"</code></td>
</tr>
</tbody></table>
<p>And now, let’s choose another arbitrary symbol to split up words besides <code>" "</code>. I’ll go with <code>e</code>.</p>

<table>
<tbody><tr>
<td><code>"to mrs savill"</code></td><td><code>" "</code></td><td><code>"ngland st p"</code></td><td><code>"t"</code></td><td><code>"rsburgh d"</code></td><td><code>"c 11th 17 you will r"</code></td><td><code>"joic"</code></td><td><code>""</code></td>

</tr>
</tbody></table>
<p>The results <em>aren’t</em> words. They’re hardly useful substrings. But, if we do this to the entire novel and plot out the rank and count of thes substrings like they <em>were</em> words, we still get a power law distribution.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="data_sparsity_files/figure-html/unnamed-chunk-24-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>In fact, if I take the top 4 most frequent letters, besides spaces, that occur in the text and use them as substring delimiters, the resulting substring distributions are <em>all</em> power-law distributed.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="data_sparsity_files/figure-html/unnamed-chunk-25-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>They even have other similar properties often associated with power law distributions in language. For example, it’s often been noted that more frequent words tend to be shorter. These weird substrings exhibit that pattern even more strongly than actual words do!</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="data_sparsity_files/figure-html/unnamed-chunk-26-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>This is all to say, be cautious about explanations for power-law distributions that are</p>
</section>
<section id="extra" class="level2">
<h2 class="anchored" data-anchor-id="extra">Extra</h2>
<p>To work out just how accurate the Good-Turing estimate is, I did the following experiment.</p>
<p>Starting from the beginning of the book, I coded each word <span class="math inline">\(w_i\)</span> for whether or not it had already appeared in the book, 1 if yes, 0 if no. This is my best shot at writing that out in mathematical notation.</p>
<p><span class="math display">\[
a_i = \left\{\begin{array}{ll}1,&amp; x_i\in x_{1:i-1}\\
                             0,&amp; x_1 \notin x_{1:i-1}\end{array}\right\}
\]</span></p>
<p>Then for every position in the book, I made a table of counts of all the words up to that point in the book so far, and got the proportion of word tokens that had appeared only once. Again, here’s my best stab at writing that out mathematically.</p>
<p><span class="math display">\[
c_{ji} = C(w_j), w_j \in x_{i:i-1}
\]</span></p>
<p><span class="math display">\[
r_i = \sum_{j=1}\left\{\begin{array}{ll}1,&amp;c_{ji}=1\\0,&amp; c_{ji} &gt;1 \end{array}\right\}
\]</span></p>
<p><span class="math display">\[
g_i = \frac{r_i}{i-1}
\]</span></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>frank_words<span class="sc">$</span>first_appearance <span class="ot">&lt;-</span> <span class="cn">NA</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>frank_words<span class="sc">$</span>first_appearance[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>frank_words<span class="sc">$</span>gt_est <span class="ot">&lt;-</span> <span class="cn">NA</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>frank_words<span class="sc">$</span>gt_est[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span><span class="fu">nrow</span>(frank_words)){</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>  i_minus <span class="ot">&lt;-</span> i<span class="dv">-1</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  prev_corp <span class="ot">&lt;-</span> frank_words<span class="sc">$</span>word[<span class="dv">1</span><span class="sc">:</span>i_minus]</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>  this_word <span class="ot">&lt;-</span> frank_words<span class="sc">$</span>word[i]</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>  frank_words<span class="sc">$</span>first_appearance[i] <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(this_word <span class="sc">%in%</span> prev_corp, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>  frank_words<span class="sc">$</span>gt_est[i] <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">table</span>(prev_corp) <span class="sc">==</span> <span class="dv">1</span>)<span class="sc">/</span>i_minus</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">

</div>
<p>Then, I plotted the Good-Turing estimate for every position as well as a non-linear logistic regression smooth.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="data_sparsity_files/figure-html/unnamed-chunk-29-1.png" class="img-fluid" width="672"></p>
</div>
</div>



</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-good1953" class="csl-entry" role="doc-biblioentry">
Good, I. J. 1953. <span>“THE POPULATION FREQUENCIES OF SPECIES AND THE ESTIMATION OF POPULATION PARAMETERS.”</span> <em>Biometrika</em> 40 (3-4): 237–64. <a href="https://doi.org/10.1093/biomet/40.3-4.237">https://doi.org/10.1093/biomet/40.3-4.237</a>.
</div>
<div id="ref-jiang2011" class="csl-entry" role="doc-biblioentry">
Jiang, Bin, and Tao Jia. 2011. <span>“Zipf’s Law for All the Natural Cities in the United States: A Geospatial Perspective.”</span> <em>International Journal of Geographical Information Science</em> 25 (8): 1269–81. <a href="https://doi.org/10.1080/13658816.2010.510801">https://doi.org/10.1080/13658816.2010.510801</a>.
</div>
<div id="ref-newman2005" class="csl-entry" role="doc-biblioentry">
Newman, Mej. 2005. <span>“Power Laws, Pareto Distributions and Zipf’s Law.”</span> <em>Contemporary Physics</em> 46 (5): 323–51. <a href="https://doi.org/10.1080/00107510500052444">https://doi.org/10.1080/00107510500052444</a>.
</div>
</div></section><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div quarto-reuse="quarto-reuse" class="quarto-appendix-contents"><div>CC-BY-SA 4.0</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../lectures/what_is_nlp/index.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">What is NLP?</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../lectures/data_processing/index.html" class="pagination-link">
        <span class="nav-page-text">Data processing</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>
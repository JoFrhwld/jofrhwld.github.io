[
  {
    "objectID": "make_qmd.html",
    "href": "make_qmd.html",
    "title": "Make research pages",
    "section": "",
    "text": "python\n\n! pip install pyzotero\n! pip install git+https://github.com/JoFrhwld/zotero2qmd.git\n\nzoetero2qmd is a quick and dirty package I wrote to convert the output from pyzotero to compatible data structures for quarto headers.\n\n\npython\n\nfrom pyzotero import zotero\nfrom zotero2qmd.zotero2qmd import item2main, main2qmd, filter_pubs\nfrom collections import Counter\nimport re\nimport yaml\nfrom pathlib import Path\n\nIf you are reusing this code, you’ll need to get your own API key: pyzotero getting started\n\n\npython\n\nkeypath = Path(\".zotero\")\nwith keypath.open() as keyfile:\n    key_text = keyfile.readline().strip()\nzot = zotero.Zotero(library_id='7642731', library_type='user', api_key=key_text)    \n\nThe zotero.Zotero.publications() method pulls down all citations you’ve added to “My Publications”.\n\n\npython\n\npubs = zot.publications()\n\nEverything that isn’t a talk is going into one big pile for now. I’ll figure out what to do with talks later. Also, I don’t know why I started using “main” to refer to the publication info.\n\n\npython\n\nfiltered_pubs = filter_pubs(pubs)\nall_mains = [item2main(x) for x in filtered_pubs]\n\nEach dictionary can be yaml dumped into valid quarto headings.\n\n\npython\n\nall_mains[0]\n\n{'params': {'key': 'BNWT43F9', 'notes': 'DOI: 10.5281/ZENODO.10212099'},\n 'author': [{'name': {'given': 'Josef', 'family': 'Fruehwald'}},\n  {'name': {'given': 'Santiago', 'family': 'Barreda'}}],\n 'title': 'fasttrackpy',\n 'date': '2023-11-28',\n 'date-format': 'YYYY',\n 'description': 'v0.3.0',\n 'abstract': 'This is a python implementation of the FastTrack method.',\n 'citation': {'type': 'software',\n  'issued': '2023-11-28',\n  'url': 'https://fasttrackiverse.github.io/fasttrackpy/',\n  'version': 'v0.3.0'}}\n\n\nIt took a bit of work to generate mostly legible but unique file names. I decided to append the Zotero key value to each.\n\n\npython\n\ndef make_file_names(all_mains):\n    first_aut = [x[\"author\"][0][\"name\"][\"family\"] for x in all_mains]\n    years = [x[\"date\"].split(\"-\")[0] for x in all_mains]\n    keys = [x[\"params\"][\"key\"] for x in all_mains]\n\n    all_stem = [f\"{aut}_{year}_{key}\" for aut, year, key in zip(first_aut, years, keys)]\n\n    all_stem = [re.sub(r\"_$\", \"\", x) for x in all_stem]\n    return all_stem\n\n\n\npython\n\nall_stems = make_file_names(all_mains)\n\nI started dumping everything into “papers”… so now I’m stuck with it.\n\n\npython\n\nout_path = Path(\"research\",\"papers\")\n\nI only want to write new files, since I may manually edit the results here and there.\n\n\npython\n\nfor stem, item in zip(all_stems, all_mains):\n    out_file = out_path.joinpath(stem).with_suffix(\".qmd\")\n    if not out_file.exists():\n        with out_file.open(mode = \"w\"):\n            qmd_string = \"---\\n\"+yaml.dump(item)+\"\\n---\"\n            out_file.write_text(qmd_string)",
    "crumbs": [
      "Research",
      "Make research pages"
    ]
  },
  {
    "objectID": "teaching/courses/2017_lsa/lectures/Session_2.nb.html",
    "href": "teaching/courses/2017_lsa/lectures/Session_2.nb.html",
    "title": "Data and Data Frames",
    "section": "",
    "text": "Talk about organizing, structuring & storing your data.\nReview some important data input/output options in R.\nReview about how data frames work in R.\n\n\n\n\n\n\n\n\n\n~2 minute setup\n\n\n\nMake sure that your current RStudio project is set to your course project. Create and save your R notebook for today (I would recommend 02_lecture.Rmd). Clear the workspace of anything left over from last time with the menu options Session &gt; Clear Workspace.\nLoad the important packages for today’s work:\n\n\nr\n\nlibrary(lsa2017)\n\nError in library(lsa2017): there is no package called 'lsa2017'\n\n\nr\n\nlibrary(tidyverse)\n\nError in library(tidyverse): there is no package called 'tidyverse'",
    "crumbs": [
      "LSA 2017 Course",
      "Lectures",
      "Data and Data Frames"
    ]
  },
  {
    "objectID": "teaching/courses/2017_lsa/lectures/Session_2.nb.html#setup",
    "href": "teaching/courses/2017_lsa/lectures/Session_2.nb.html#setup",
    "title": "Data and Data Frames",
    "section": "",
    "text": "~2 minute setup\n\n\n\nMake sure that your current RStudio project is set to your course project. Create and save your R notebook for today (I would recommend 02_lecture.Rmd). Clear the workspace of anything left over from last time with the menu options Session &gt; Clear Workspace.\nLoad the important packages for today’s work:\n\n\nr\n\nlibrary(lsa2017)\n\nError in library(lsa2017): there is no package called 'lsa2017'\n\n\nr\n\nlibrary(tidyverse)\n\nError in library(tidyverse): there is no package called 'tidyverse'",
    "crumbs": [
      "LSA 2017 Course",
      "Lectures",
      "Data and Data Frames"
    ]
  },
  {
    "objectID": "teaching/courses/2017_lsa/lectures/Session_2.nb.html#general-principles-of-data-collection",
    "href": "teaching/courses/2017_lsa/lectures/Session_2.nb.html#general-principles-of-data-collection",
    "title": "Data and Data Frames",
    "section": "General Principles of Data Collection",
    "text": "General Principles of Data Collection\n\nOver-collect (for some things)\nWhen collecting data in the first place, over-collect if at all possible or ethical. The world is a very complex place, so there is no way you could cram it all into a bottle, but give it your best shot! If during the course of your data analysis, you find that it would have been really useful to have data on, say, duration, as well as formant frequencies, it becomes costly to recollect that data, especially if you haven’t laid the proper trail for yourself. On the other hand, automation of acoustic analysis or data processing can cut down on this costliness.\nThis doesn’t go for personal information on human subjects, though. It’s important from an ethics standpoint to ask for everything you’ll need, but not more. You don’t want to collect an enormous demographic profile on your participants if you won’t wind up using it, especially if you know you won’t use it to begin with.\n\n\nPreserve HiD Info\nIf, for instance, you’re collecting data on the effect of voicing on preceding vowel duration, preserve high dimensional data coding, like Lexical Item, or the transcription of the following segment. These high dimensional codings probably won’t be too useful for your immediate analysis, but they will allow you to procedurally extract additional features from them at a later time. For example, if you have a column called fol_seg, which is just a transcription of the following segment, it is easy create a new column called manner with code that looks like this:\n\n\nr\n\ntable(iy_ah$fol_seg)\n\nError in eval(expr, envir, enclos): object 'iy_ah' not found\n\n\n\n\nr\n\niy_ah &lt;- iy_ah %&gt;%\n  mutate(\n    manner = recode(\n      fol_seg, \n      B = 'stop',\n      CH = 'affricate',\n      D = 'stop',\n      DH = 'fricative',\n      `F` = 'fricative',\n      G = 'stop',\n      HH = 'fricative',\n      JH = 'affricate',\n      K = 'stop',\n      L = 'liquid',\n      M = 'nasal',\n      N = 'nasal',\n      NG = 'nasal',\n      P = 'stop',\n      R = 'liquid',\n      S = 'fricative',\n      SH = 'fricative',\n      SP = 'pause',\n      `T` = 'stop',\n      TH = 'fricative',\n      V = 'fricative',\n      W = 'glide',\n      Y = 'glide',\n      Z = 'fricative',\n      ZH = 'fricative',\n      .default = 'vowel'\n    )\n  )\n\nError in iy_ah %&gt;% mutate(manner = recode(fol_seg, B = \"stop\", CH = \"affricate\", : could not find function \"%&gt;%\"\n\n\nr\n\ntable(iy_ah$manner)\n\nError in eval(expr, envir, enclos): object 'iy_ah' not found\n\n\n\n\nLeave A Trail of Crumbs\nBe sure to answer this question: How can I preserve a record of this observation in such a way that I can quickly return to it and gather more data on it if necessary? If you fail to successfully answer this question, then you’ll be lost in the woods if you ever want to restudy, and the only way home is to replicate the study from scratch.\n\n\nGive Meaningful Names\nGive meaningful names to both the names of predictor columns, as well as to labels of nominal observations. Keeping a readme describing the data is still a good idea, but at least now the data is approachable at first glance.\n\n\nDistinguish between 0 and NA\nI have worked with some spreadsheets where missing data was given a value of 0, which will mess things up. For example, /oy/ is a fairly rarely occurring phoneme in English, and it’s possible that a speaker won’t produce any tokens in a short interview. In a spreadsheet of mean F1 and F2 for all vowels, that speaker should get an NA for /oy/, not 0.",
    "crumbs": [
      "LSA 2017 Course",
      "Lectures",
      "Data and Data Frames"
    ]
  },
  {
    "objectID": "teaching/courses/2017_lsa/lectures/Session_2.nb.html#storing-data",
    "href": "teaching/courses/2017_lsa/lectures/Session_2.nb.html#storing-data",
    "title": "Data and Data Frames",
    "section": "Storing Data",
    "text": "Storing Data\nWhen we store data, it should be:\n\nRaw\n\nRaw data is the most useful data. It’s impossible to move down to smaller granularity from a coarser, summarized granularity. Summary tables etc. are nice for publishing in a paper document, but raw data is what we need for asking novel research questions with old data.\n\nOpen Formatted\n\nDo not use proprietary database software for long term storage of your data. I have enough heard stories about interesting data sets that are no longer accessible for research either because the software they are stored in is defunct, or current versions are not backwards compatible. At that point, your data is property of Microsoft, or whoever. Store your data as raw text, delimited in some way (I prefer tabs).\n\nConsistent\n\nI think this is most important when you may have data in many separate files. Each file and its headers should be consistently named and formatted. They should be consistently delimited and commented also. There is nothing worse than inconsistent headers and erratic comments, labels, headers or NA characters in a corpus. (Automation also helps here.)\n\nDocumented\n\nProduce a readme describing the data, how it was collected and processed, and describe every variable and its possible values.",
    "crumbs": [
      "LSA 2017 Course",
      "Lectures",
      "Data and Data Frames"
    ]
  },
  {
    "objectID": "teaching/courses/2017_lsa/lectures/Session_2.nb.html#breaking-bad-spreadsheet-habits",
    "href": "teaching/courses/2017_lsa/lectures/Session_2.nb.html#breaking-bad-spreadsheet-habits",
    "title": "Data and Data Frames",
    "section": "Breaking Bad Spreadsheet Habits",
    "text": "Breaking Bad Spreadsheet Habits\nLet’s start off by looking at a picture of a data organization approach that might look familiar, and is a very bad way to do things:\n\n\n\n\n\nThis spreadsheet has a fairly strict organizational structure, but is virtuously hopeless for doing any kind of serious statistical analysis. It’s also verging on irreparable using R. This because the data in this spreadsheet is organized to be easy to look at with your eyeballs 👀.\nBut looking at neatly organized data in a spreadsheet is not a statistical analysis technique. So we need to start organizing our data in a way that isn’t easy to look at, but is easy to graph and analyze.",
    "crumbs": [
      "LSA 2017 Course",
      "Lectures",
      "Data and Data Frames"
    ]
  },
  {
    "objectID": "teaching/courses/2017_lsa/lectures/Session_2.nb.html#better-habits",
    "href": "teaching/courses/2017_lsa/lectures/Session_2.nb.html#better-habits",
    "title": "Data and Data Frames",
    "section": "Better Habits",
    "text": "Better Habits\nEveryone working with data (in R or otherwise) should read Hadley Wickham’s paper on Tidy Data: https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html If you are coming off of organizing your data like the picture above, there are a few guidelines not discussed in that paper, namely:\n\nFollow these rules\n\nThe first row of the data must be the names of the data columns.\nAll other rows must be the data, and nothing else.\nYou cannot use empty rows or empty columns as visual aids to look at the data.\nThe spreadsheet must not contain any summary cells. No final row called “Average” or final column called “Total”. We can create these in R, and they make data processing more complicated if they’re included in the raw data.\n\n\n\nSemantics of Data Structure\nIn the semantics of data structure Wickham lays out, there are three important primitives:\n\nVariables\nValues\nObservations\n\n\nDefining the primitives\n\nVariables\nVariables are the collections of values of interest in data analysis. For example, let’s say you were doing a study on unnormalized vowel space size by just looking at /i:/ and /ɑ/. The variables in that study could be:\n\nspeaker\nword\nphoneme\nduration\nF1\nF2\nword_frequency\n\n\n\nValues\nValues are, as the name implies, the possible values that each variable can have, for example:\n\nspeaker: \"Oakley\", \"Charlie\", \"Azaria\", ...\nword: \"street\", \"thirteen\", \"not\", \"got\", ...\nphoneme: \"iy\", \"ah\"\n\n\n\nObservations\nAn observation is the minimal unit across which all variables are collected. For example, in the vowel space study, one observation would be one instance of an uttered vowel for which you record who the speaker was, the word, the duration, F1, F2, etc.\n\n\n\nOrganizing data with these primitives\nOnce you’ve thought through what the variables, values and observations are for your study, the principle of how to organize them is simple:\n\nEach variable forms a column.\nEach observation forms a row.\n\nFor the vowel space size study, you might want to wind up with a plot that looks like this:\n\n\nError in iy_ah %&gt;% group_by(idstring, sex, age, plt_vclass) %&gt;% summarise(F1 = mean(F1), : could not find function \"%&gt;%\"\n\n\nIt wouldn’t be uncommon to see the data untidily organized like this:\n\n\nError in iy_ah %&gt;% group_by(idstring, sex, age, plt_vclass) %&gt;% summarise(F1 = mean(F1), : could not find function \"%&gt;%\"\n\n\n\n\n\n\n\n\n~5 minute activity\n\n\n\nIn small groups, figure out the following:\n\nWhat are the variables in the data frame above?\nWhat are the values?\nWhat are the observations?\nHow should the table above be re-organized?\n\n\n\nError in iy_ah %&gt;% group_by(idstring, sex, age, plt_vclass) %&gt;% summarise(F1 = mean(F1), : could not find function \"%&gt;%\"",
    "crumbs": [
      "LSA 2017 Course",
      "Lectures",
      "Data and Data Frames"
    ]
  },
  {
    "objectID": "teaching/courses/2017_lsa/lectures/Session_2.nb.html#finding-your-way-around",
    "href": "teaching/courses/2017_lsa/lectures/Session_2.nb.html#finding-your-way-around",
    "title": "Data and Data Frames",
    "section": "Finding your way around",
    "text": "Finding your way around\nThe pitch data frame has four rows, and three columns. The rows are just numbered 1 through 4, and the three columns are named speaker_names, ages and F0. To find out how many rows and columns a data frame has, you can use the nrow() and ncol() functions.\n\n\nr\n\nnrow(pitch)\n\n[1] 4\n\n\nr\n\nncol(pitch)\n\n[1] 3\n\n\nMost data frames you’re going to work with have a lot more rows than that. For example, iy_ah is a data frame that is bundled in the lsa2017 package.\n\n\nr\n\nnrow(iy_ah)\n\nError in eval(expr, envir, enclos): object 'iy_ah' not found\n\n\nThat’s too many rows to look at just in the console. One option is to use the head() function, that just prints the first 6 rows.\n\n\nr\n\nhead(iy_ah)\n\nError in eval(expr, envir, enclos): object 'iy_ah' not found\n\n\nAnother option is to use the summary() function.\n\n\nr\n\nsummary(iy_ah)\n\nError in eval(expr, envir, enclos): object 'iy_ah' not found\n\n\nsummary() is a function that works on almost every kind of object.",
    "crumbs": [
      "LSA 2017 Course",
      "Lectures",
      "Data and Data Frames"
    ]
  },
  {
    "objectID": "teaching/courses/2017_lsa/lectures/Session_2.nb.html#indexing-data-frames",
    "href": "teaching/courses/2017_lsa/lectures/Session_2.nb.html#indexing-data-frames",
    "title": "Data and Data Frames",
    "section": "Indexing Data Frames",
    "text": "Indexing Data Frames\nSince data frames are 2 dimensional (rows are one dimension, columns are another), the way you index them is a little bit more complicated than with vectors. It still uses square brackets, though, but these square brackets have two positions:\n\ndf[row number, column number]\n\nIf you specify a specific row number, but leave the column number blank, you’ll get back that row and all columns.\n\n\nr\n\npitch[1,]\n\n  speaker_names ages  F0\n1       Charlie   18 114\n\n\nAlternatively, if you specify just the column number, but leave the rows blank, you’ll get back all of the values for that column.\n\n\nr\n\npitch[,2]\n\n[1] 18 35 41 62\n\n\nWhen you specify both, you get back the value in the specified row and column\n\n\nr\n\npitch[1,2]\n\n[1] 18\n\n\nHowever, there is a special indexing operator for data frames that take advantage of their named columns: $.\n\ndf$column_name\n\n\n\nr\n\npitch$speaker_names\n\n[1] \"Charlie\" \"Skyler\"  \"Sawyer\"  \"Jamie\"  \n\n\nAfter accessing the column of a data frame, you can index it just like it’s a vector.\n\n\nr\n\npitch$speaker_names[1]\n\n[1] \"Charlie\"\n\n\nIf you really want to, you can do logical indexing of data frames like so:\n\n\nr\n\npitch[pitch$speaker_names == \"Charlie\", ]\n\n  speaker_names ages  F0\n1       Charlie   18 114\n\n\nBut there’s also a function called filter() that you can use to do the same thing. filter() takes a data frame as its first argument, and then a logical statement referring to one or more of the data frame’s columns.\n\n\nr\n\nfilter(pitch, speaker_names == \"Charlie\")\n\nError in eval(expr, envir, enclos): object 'speaker_names' not found\n\n\nr\n\nfilter(pitch, ages &gt; 18, F0 &gt; 190)\n\nError in eval(expr, envir, enclos): object 'F0' not found\n\n\n\n\n\n\n\n\n~5 minute activity\n\n\n\nFirst, review the documentation of the iy_ah data set with ?iy_ah. Using filter() and nrow(), find out what percent of /i:/ tokens have a duration less than 90ms (0.09s).",
    "crumbs": [
      "LSA 2017 Course",
      "Lectures",
      "Data and Data Frames"
    ]
  },
  {
    "objectID": "teaching/courses/2017_lsa/lectures/Session_2.nb.html#gathering-columns",
    "href": "teaching/courses/2017_lsa/lectures/Session_2.nb.html#gathering-columns",
    "title": "Data and Data Frames",
    "section": "Gathering Columns",
    "text": "Gathering Columns\nThe gather() function makes wide data long. It takes the following arguments:\n\ngather(data, key, value, cols)\n\n\ndata\n\nObviously, the data you want to reshape. must be a data frame.\n\nkey and value\n\nThese are new column names that you want to create. gather() is going to take the column names and put them in the column you give to key, and the values from all the cells and put them in the column you call value.\n\ncols\n\nAn indication of which columns you want to gather, either a vector of column names, a vector of column numbers, or some specialized methods for gather() that we’ll discuss.\n\n\nHere’s how that’ll work for the fruit data. We’ll tell gather() to gather columns 2 through 5.\n\n\nr\n\nfruit_long &lt;- gather(data = fruit,\n                     key = fruit_behavior,\n                     value = number,\n                     2:5)\n\nError in gather(data = fruit, key = fruit_behavior, value = number, 2:5): could not find function \"gather\"\n\n\nError in eval(expr, envir, enclos): object 'fruit_long' not found\ngather() has returned a new data frame. It has created a new column called fruit_behavior, because we told it to with the key argument, and it has created a new column called number, because we told it to with the value function. It has taken all of the column names of the columns we told it to gather, and put them into the fruit_behavior column, and the numeric values from the columns we told it to gather, and put them into the number column. It has also repeated the rows of the other columns (person) as logically necessary.\nNow, we told it to gather column numbers 2 through 5, but this would have also worked:\n\n\nr\n\ngather(data = fruit, \n       key = fruit_behavior, \n       value = number, \n       c(\"apples_bought\",\"apples_ate\", \"oranges_bought\", \"oranges_ate\"))\n\nError in gather(data = fruit, key = fruit_behavior, value = number, c(\"apples_bought\", : could not find function \"gather\"\n\n\ngather() also has a more convenient method of specifying the columns you want to gather by passing it a named range of columns. We want to gather all columns from apples_bought to oranges_ate, so we can tell it to do so with apples_bought:oranges_ate.\n\n\nr\n\ngather(data = fruit, \n       key = fruit_behavior, \n       value = number, \n       apples_bought:oranges_ate)\n\nError in gather(data = fruit, key = fruit_behavior, value = number, apples_bought:oranges_ate): could not find function \"gather\"\n\n\nOk, let’s do this now to the iy_ah_wide data, gathering all of the columns from ah_F1 to iy_F2.\n\n\nr\n\niy_ah_step1 &lt;- gather(data = iy_ah_wide, \n                      key = vowel_formant, \n                      value = hz, \n                      ah_F1:iy_F2)\n\nError in gather(data = iy_ah_wide, key = vowel_formant, value = hz, ah_F1:iy_F2): could not find function \"gather\"\n\n\nr\n\niy_ah_step1\n\nError in eval(expr, envir, enclos): object 'iy_ah_step1' not found\n\n\nFor the fruit data, the only un-gathered column was person, but for iy_ah_wide, idstring, age, sex, and year, were all ungathered. Here you can see how all rows of ungathered columns are repeated as logically necessary.",
    "crumbs": [
      "LSA 2017 Course",
      "Lectures",
      "Data and Data Frames"
    ]
  },
  {
    "objectID": "teaching/courses/2017_lsa/lectures/Session_2.nb.html#separating-columns",
    "href": "teaching/courses/2017_lsa/lectures/Session_2.nb.html#separating-columns",
    "title": "Data and Data Frames",
    "section": "Separating Columns",
    "text": "Separating Columns\nThere is still a problem with both the fruit_long and the iy_ah_step1 data frames, which is that two different kinds of data are merged within one column. For iy_ah_step1, the vowel class and formant variable are merged together (e.g. ah_F1) and for fruit_long, the fruit and behavior are merged together (e.g. apple_bought). We need to separate these, with a very aptly named function called separate()\n\nseparate(data, col, into, sep)\n\n\ndata\n\nAgain,the data frame you want to do this separation to.\n\ncol\n\nThe name of the column you want to separate.\n\ninto\n\nA character vector of the new column names you want to create.\n\nsep\n\nThe character or regex pattern you want to use to split up the values in col.\n\n\nHere’s how it works for fruit_long.\n\n\nr\n\nfruit_separate &lt;- separate(data = fruit_long,\n                           col = fruit_behavior,\n                           into = c(\"fruit\", \"behavior\"),\n                           sep = \"_\")\n\nError in separate(data = fruit_long, col = fruit_behavior, into = c(\"fruit\", : could not find function \"separate\"\n\n\nError in eval(expr, envir, enclos): object 'fruit_separate' not found\nIt has returned a new data frame with the fruit_behavior column split into two new columns, named after what I passed to the into argument. It split up fruit_behavior based on what I passed to sep, which was the underscore character.\nLet’s do this for iy_ah_step1 now.\n\n\nr\n\niy_ah_step2 &lt;- separate(iy_ah_step1, \n                        vowel_formant, \n                        into = c(\"vowel\", \"formant\"),\n                        sep = \"_\")\n\nError in separate(iy_ah_step1, vowel_formant, into = c(\"vowel\", \"formant\"), : could not find function \"separate\"\n\n\nr\n\niy_ah_step2\n\nError in eval(expr, envir, enclos): object 'iy_ah_step2' not found\n\n\nWe now have two separate columns for vowel and formant.\n\nHygiene\nI have been very helpful and used underscores to merge together the values we want to separate. Be helpful to yourself, and be consistent in the semantics of how you used potential delimiters like - and _. Here’s an example of being helpful to yourself:\nproject_subject_firstname-lastname\n\nEDI_1_Stuart-Duddingston\nEDI_2_Connor-Black-Macdowall\nEDI_3_Mhairi\nThis is helpful, because when you separate by underscore, you’ll have something tidy\nEDI    1    Stuart-Duddingston\nEDI    2    Connor-Black-Macdowall\nEDI    3    Mhairi\nIf you used - for everything, you’ll have chaos when you try to separate them because some speakers have “double barreled” names, and some speakers have only first names:\n# Input:\nEDI-1-Stuart-Duddingston\nEDI-2-Connor-Black-Macdowall\nEDI-3-Mhairi\n\n# Becomes\n\nEDI    1    Stuart    Duddingston\nEDI    2    Connor    Black        Macdowall\nEDI    3    Mhairi\nThis goes beyond R programming. You should make some decisions and stick with them for all of your data analysis, including file naming, Praat tier naming, etc.",
    "crumbs": [
      "LSA 2017 Course",
      "Lectures",
      "Data and Data Frames"
    ]
  },
  {
    "objectID": "teaching/courses/2017_lsa/lectures/Session_2.nb.html#spreading-columns",
    "href": "teaching/courses/2017_lsa/lectures/Session_2.nb.html#spreading-columns",
    "title": "Data and Data Frames",
    "section": "Spreading columns",
    "text": "Spreading columns\nWe’ve got one last step, which is spreading the values in some rows across the column space. With the fruit data, we might not want a column called behavior, but actually have two columns called bought and ate. For the vowel data, we definitely don’t want one column called formant. We want one called F1 and one called F2. We can do this with the spread() function.\n\nspread(data, key, value)\n\n\ndata\n\nAgain, the data we want to work with.\n\nkey\n\nThe column whose values you want to spread across the column space.\n\nvalue\n\nThe column with values that you want to fill in the cells.\n\n\nHere’s how that looks with the fruit_separate data.\n\n\nr\n\nfruit_spread &lt;- spread(data = fruit_separate,\n                       key = behavior,\n                       value = number)\n\nError in spread(data = fruit_separate, key = behavior, value = number): could not find function \"spread\"\n\n\nError in eval(expr, envir, enclos): object 'fruit_spread' not found\nThis has created a new data frame. I told spread() to spread the values in behavior across the column space. Because it had only two unique values in it (bought and ate), it has created two new columns called bought and ate. After creating these new columns, it had to fill in the new cells with some values, and I told it to use the values in number for that.\nHere’s how that works with iy_ah_step2.\n\n\nr\n\niy_ah_step3 &lt;- spread(data = iy_ah_step2,\n                      key = formant,\n                      value = hz)\n\nError in spread(data = iy_ah_step2, key = formant, value = hz): could not find function \"spread\"\n\n\nr\n\niy_ah_step3\n\nError in eval(expr, envir, enclos): object 'iy_ah_step3' not found\n\n\nNow, we’ve finally gotten to a tidy data format. In our next meeting, we’ll discuss how to chain these three functions into one easy to read process.\n\nIdiom\nYou might have noticed that in the functions above, I’ve put a new line between individual function arguments. I’ve done this because white-space doesn’t matter when it comes to R. I could have written these with just spaces between each argument, but that would be too visually crowded.\n\n\nr\n\n# compare\n\n# One line\nfruit_separate &lt;- separate(data = fruit_long, col = fruit_behavior, into = c(\"fruit\", \"behavior\"), sep = \"_\")\n\nError in separate(data = fruit_long, col = fruit_behavior, into = c(\"fruit\", : could not find function \"separate\"\n\n\nr\n\n# New Lines\nfruit_separate &lt;- separate(data = fruit_long, \n                           col = fruit_behavior, \n                           into = c(\"fruit\", \"behavior\"), \n                           sep = \"_\")\n\nError in separate(data = fruit_long, col = fruit_behavior, into = c(\"fruit\", : could not find function \"separate\"\n\n\nI encourage you to use new lines similarly to give yourself “some space to breathe”. Don’t be shy about it. But, if you put newlines between some arguments, you should really put new lines between all arguments.",
    "crumbs": [
      "LSA 2017 Course",
      "Lectures",
      "Data and Data Frames"
    ]
  },
  {
    "objectID": "teaching/courses/2017_lsa/lectures/Session_2.nb.html#footnotes",
    "href": "teaching/courses/2017_lsa/lectures/Session_2.nb.html#footnotes",
    "title": "Data and Data Frames",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nMy personal aesthetic preference is for tab-delimited files.↩︎\nThis doesn’t work if the file is behind encryption, i.e. if it begins with https://.↩︎\n“The Donner Party (sometimes called the Donner-Reed Party) was a group of American pioneer migrants who set out for California in a wagon train. Delayed by a series of mishaps, they spent the winter of 1846–47 snowbound in the Sierra Nevadas. Some of the migrants resorted to cannibalism to survive, eating those who had succumbed to starvation and sickness.” https://en.wikipedia.org/wiki/Donner_Party↩︎",
    "crumbs": [
      "LSA 2017 Course",
      "Lectures",
      "Data and Data Frames"
    ]
  },
  {
    "objectID": "teaching/courses/2017_lsa/index.html",
    "href": "teaching/courses/2017_lsa/index.html",
    "title": "LSA 2017 Statistical Modelling with R",
    "section": "",
    "text": "Meeting 1: Introduction to R\nMeeting 2: Data and Data Frames\nMeeting 3: Piping and Split-Apply-Combine\nMeeting 4: Plotting in ggplot2\nMeeting 5: Fitting Linear Models\nMeeting 6: More on interpreting & fitting linear models\nMeeting 7: Mixed Effects models\nMeeting 8: Model Comparison and Bootstrapping\n\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\norder\n\n\nTitle\n\n\nReading Time\n\n\n\n\n\n\n\n\n\n1\n\n\nIntroduction to R\n\n\n19 min\n\n\n\n\n\n\n\n2\n\n\nData and Data Frames\n\n\n24 min\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "LSA 2017 Course",
      "LSA 2017 Statistical Modelling with R"
    ]
  },
  {
    "objectID": "software/packages/fave-recode.html",
    "href": "software/packages/fave-recode.html",
    "title": "fave-recode",
    "section": "",
    "text": "CitationBibTeX citation:@software{fruehwald2023,\n  author = {Fruehwald, Josef},\n  title = {Fave-Recode},\n  version = {v0.2.0},\n  date = {2023-11-21},\n  url = {https://forced-alignment-and-vowel-extraction.github.io/fave-recode/},\n  doi = {10.5281/ZENODO.10392791},\n  langid = {en},\n  abstract = {The idea behind fave-recode is that no matter how much you\n    may adjust the dictionary of a forced-aligner, you may still want to\n    make programmatic changes to the output.}\n}\nFor attribution, please cite this work as:\nFruehwald, Josef. 2023. “Fave-Recode.” https://doi.org/10.5281/ZENODO.10392791."
  },
  {
    "objectID": "software/packages/densityarea.html",
    "href": "software/packages/densityarea.html",
    "title": "densityarea: Polygons of Bivariate Density Distributions",
    "section": "",
    "text": "CitationBibTeX citation:@software{fruehwald2023,\n  author = {Fruehwald, Josef},\n  title = {Densityarea: {Polygons} of {Bivariate} {Density}\n    {Distributions}},\n  version = {v0.1.0},\n  date = {2023-10-02},\n  url = {https://jofrhwld.github.io/densityarea/},\n  doi = {10.5281/ZENODO.10393190},\n  langid = {en},\n  abstract = {Areas of Bivarate Density Distributions}\n}\nFor attribution, please cite this work as:\nFruehwald, Josef. 2023. “Densityarea: Polygons of Bivariate\nDensity Distributions.” https://doi.org/10.5281/ZENODO.10393190."
  },
  {
    "objectID": "software/index.html",
    "href": "software/index.html",
    "title": "Software",
    "section": "",
    "text": "aligned-textgrid\n\n\n\nfave\n\n\ntextgrids\n\n\npython\n\n\n\nThe aligned-textgrid package provides a python interface for representing and operating on…\n\n\n\nJosef Fruehwald, Christian Brickhouse\n\n\nNov 22, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndensityarea: Polygons of Bivariate Density Distributions\n\n\n\nR\n\n\nphonetics\n\n\ndata-viz\n\n\n\nAreas of Bivarate Density Distributions\n\n\n\nJosef Fruehwald\n\n\nOct 2, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfasttrackpy\n\n\n\npython\n\n\nphonetics\n\n\n\nThis is a python implementation of the FastTrack method.\n\n\n\nJosef Fruehwald, Santiago Barreda\n\n\nNov 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfave-recode\n\n\n\nfave\n\n\ntextgrids\n\n\npython\n\n\n\nThe idea behind fave-recode is that no matter how much you may adjust the dictionary of a…\n\n\n\nJosef Fruehwald\n\n\nNov 21, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsyllabifyr: Syllabifier for CMU Dictionary Transcriptions\n\n\n\nR\n\n\n\nThe goal of syllabifyr is to provide tidy syllabification of phonetic transcriptions. So far…\n\n\n\nJosef Fruehwald\n\n\nOct 24, 2020\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "research/papers/Tanner_2020_GH2LZM4Y.html",
    "href": "research/papers/Tanner_2020_GH2LZM4Y.html",
    "title": "Toward “English” Phonetics: Variability in the Pre-consonantal Voicing Effect Across English Dialects and Speakers",
    "section": "",
    "text": "CitationBibTeX citation:@article{tanner2020,\n  author = {Tanner, James and Sonderegger, Morgan and Stuart-Smith, Jane\n    and Fruehwald, Josef},\n  title = {Toward “{English}” {Phonetics:} {Variability} in the\n    {Pre-consonantal} {Voicing} {Effect} {Across} {English} {Dialects}\n    and {Speakers}},\n  journal = {Frontiers in Artificial Intelligence},\n  volume = {3},\n  pages = {38},\n  date = {2020/05/29},\n  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7861323/},\n  doi = {10.3389/frai.2020.00038},\n  langid = {en},\n  abstract = {Recent advances in access to spoken-language corpora and\n    development of speech processing tools have made possible the\n    performance of “large-scale” phonetic and sociolinguistic research.\n    This study illustrates the usefulness of such a large-scale\n    approach—using data from multiple corpora across a range of English\n    dialects, collected, and analyzed with the SPADE project—to examine\n    how the pre-consonantal Voicing Effect (longer vowels before voiced\n    than voiceless obstruents, in e.g., bead vs. beat) is realized in\n    spontaneous speech, and varies across dialects and individual\n    speakers. Compared with previous reports of controlled laboratory\n    speech, the Voicing Effect was found to be substantially smaller in\n    spontaneous speech, but still influenced by the expected range of\n    phonetic factors. Dialects of English differed substantially from\n    each other in the size of the Voicing Effect, whilst individual\n    speakers varied little relative to their particular dialect. This\n    study demonstrates the value of large-scale phonetic research as a\n    means of developing our understanding of the structure of speech\n    variability, and illustrates how large-scale studies, such as those\n    carried out within SPADE, can be applied to other questions in\n    phonetic and sociolinguistic research.}\n}\nFor attribution, please cite this work as:\nTanner, James, Morgan Sonderegger, Jane Stuart-Smith, and Josef\nFruehwald. 2020–5AD. “Toward ‘English’ Phonetics:\nVariability in the Pre-Consonantal Voicing Effect Across English\nDialects and Speakers.” Frontiers in Artificial\nIntelligence 3: 38. https://doi.org/10.3389/frai.2020.00038."
  },
  {
    "objectID": "research/papers/Rosenfelder_2022_TRXWWXD2.html",
    "href": "research/papers/Rosenfelder_2022_TRXWWXD2.html",
    "title": "FAVE (Forced Alignment and Vowel Extraction) Program Suite v2.0.0",
    "section": "",
    "text": "CitationBibTeX citation:@software{rosenfelder2022,\n  author = {Rosenfelder, Ingrid and Fruehwald, Josef and Brickhouse,\n    Christian and Evanini, Keelan and Seyfarth, Scott and Gorman, Kyle\n    and Prichard, Hilary and Yuan, Jiahong},\n  title = {FAVE {(Forced} {Alignment} and {Vowel} {Extraction)}\n    {Program} {Suite} V2.0.0},\n  version = {v2.0.0},\n  date = {2022},\n  url = {https://github.com/JoFrhwld/FAVE},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nRosenfelder, Ingrid, Josef Fruehwald, Christian Brickhouse, Keelan\nEvanini, Scott Seyfarth, Kyle Gorman, Hilary Prichard, and Jiahong Yuan.\n2022. “FAVE (Forced Alignment and Vowel Extraction) Program Suite\nV2.0.0.” https://github.com/JoFrhwld/FAVE."
  },
  {
    "objectID": "research/papers/Rosenfelder_2011_M3E7A7LS.html",
    "href": "research/papers/Rosenfelder_2011_M3E7A7LS.html",
    "title": "FAVE (Forced Alignment and Vowel Extraction) Program Suite.",
    "section": "",
    "text": "CitationBibTeX citation:@software{rosenfelder2011,\n  author = {Rosenfelder, Ingrid and Fruehwald, Josef and Evanini, Keelan\n    and Yuan, Jiahong},\n  title = {FAVE {(Forced} {Alignment} and {Vowel} {Extraction)}\n    {Program} {Suite.}},\n  version = {v0.0.0},\n  date = {2011},\n  url = {http://fave.ling.upenn.edu/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nRosenfelder, Ingrid, Josef Fruehwald, Keelan Evanini, and Jiahong Yuan.\n2011. “FAVE (Forced Alignment and Vowel Extraction) Program\nSuite.” http://fave.ling.upenn.edu/."
  },
  {
    "objectID": "research/papers/Mielke_2019_U5C56KNR.html",
    "href": "research/papers/Mielke_2019_U5C56KNR.html",
    "title": "Age vectors vs. axes of intraspeaker variation in vowel formants measured automatically from several English speech corpora.",
    "section": "",
    "text": "CitationBibTeX citation:@article{mielke2019,\n  author = {Mielke, Jeff and Thomas, Erik R and Fruehwald, Josef and\n    McAuliffe, Michael and Sonderegger, Morgan and Stuart-Smith, Jane\n    and Dodsworth, Robin},\n  title = {Age Vectors Vs. Axes of Intraspeaker Variation in Vowel\n    Formants Measured Automatically from Several {English} Speech\n    Corpora.},\n  journal = {Proceedings of the 19th International Congress of Phonetic\n    Sciences, Melbourne, Australia 2019},\n  date = {2019},\n  url = {https://assta.org/proceedings/ICPhS2019/papers/ICPhS_1307.pdf},\n  langid = {en},\n  abstract = {To test the hypothesis that intraspeaker variation in\n    vowel formants is related to the direction of diachronic change, we\n    compare the direction of change in apparent time with the axis of\n    intraspeaker variation in F1 and F2 for vowel phonemes in several\n    corpora of North American and Scottish English. These vowels were\n    measured automatically with a scheme (tested on hand-measured\n    vowels) that considers the frequency, bandwidth, and amplitude of\n    the ﬁrst three formants in reference to a prototype. In the corpus\n    data, we ﬁnd that the axis of intraspeaker variation is typically\n    aligned vertically, presumably corresponding to the degree of jaw\n    opening for individual tokens, but for the North American GOOSE\n    vowel, the axis of intraspeaker variation is aligned with the\n    (horizontal) axis of diachronic change for this vowel across North\n    America. This may help to explain why fronting and unrounding of\n    high back vowels are common shifts across languages.}\n}\nFor attribution, please cite this work as:\nMielke, Jeff, Erik R Thomas, Josef Fruehwald, Michael McAuliffe, Morgan\nSonderegger, Jane Stuart-Smith, and Robin Dodsworth. 2019. “Age\nVectors Vs. Axes of Intraspeaker Variation in Vowel Formants Measured\nAutomatically from Several English Speech Corpora.”\nProceedings of the 19th International Congress of Phonetic Sciences,\nMelbourne, Australia 2019. https://assta.org/proceedings/ICPhS2019/papers/ICPhS_1307.pdf."
  },
  {
    "objectID": "research/papers/Fruehwald_2024_WJ9M3PEN.html",
    "href": "research/papers/Fruehwald_2024_WJ9M3PEN.html",
    "title": "aligned-textgrid: Lightweight access to structured phonetic data",
    "section": "",
    "text": "CitationBibTeX citation:@article{fruehwald2024,\n  author = {Fruehwald, Josef and Brickhouse, Christian},\n  title = {Aligned-Textgrid: {Lightweight} Access to Structured Phonetic\n    Data},\n  journal = {Proceedings of the Society for Computation in Linguistics\n    (SCiL) 2024},\n  pages = {329-330},\n  date = {2024-06-24},\n  url = {https://openpublishing.library.umass.edu/scil/article/id/2217/},\n  doi = {10.7275/SCIL.2217},\n  langid = {en},\n  abstract = {The goal of aligned-textgrid is to provide lightweight,\n    scriptable access to the structured data produced by\n    forced-aligners. The library is written in python, and currently\n    available on the Python Package Index.}\n}\nFor attribution, please cite this work as:\nFruehwald, Josef, and Christian Brickhouse. 2024.\n“Aligned-Textgrid: Lightweight Access to Structured Phonetic\nData.” Proceedings of the Society for Computation in\nLinguistics (SCiL) 2024, June, 329–30. https://doi.org/10.7275/SCIL.2217."
  },
  {
    "objectID": "research/papers/Fruehwald_2023_W27UEZSV.html",
    "href": "research/papers/Fruehwald_2023_W27UEZSV.html",
    "title": "densityarea: Polygons of Bivariate Density Distributions",
    "section": "",
    "text": "CitationBibTeX citation:@software{fruehwald2023,\n  author = {Fruehwald, Josef},\n  title = {Densityarea: {Polygons} of {Bivariate} {Density}\n    {Distributions}},\n  version = {v0.1.0},\n  date = {2023-10-02},\n  url = {https://jofrhwld.github.io/densityarea/},\n  doi = {10.5281/ZENODO.10393190},\n  langid = {en},\n  abstract = {Areas of Bivarate Density Distributions}\n}\nFor attribution, please cite this work as:\nFruehwald, Josef. 2023. “Densityarea: Polygons of Bivariate\nDensity Distributions.” https://doi.org/10.5281/ZENODO.10393190."
  },
  {
    "objectID": "research/papers/Fruehwald_2023_GY5I9QMZ.html",
    "href": "research/papers/Fruehwald_2023_GY5I9QMZ.html",
    "title": "aligned-textgrid",
    "section": "",
    "text": "CitationBibTeX citation:@software{fruehwald2023,\n  author = {Fruehwald, Josef and Brickhouse, Christian},\n  title = {Aligned-Textgrid},\n  version = {v0.5.0},\n  date = {2023-11-22},\n  url = {https://forced-alignment-and-vowel-extraction.github.io/alignedTextGrid/},\n  doi = {10.5281/zenodo.10190692},\n  langid = {en},\n  abstract = {The aligned-textgrid package provides a python interface\n    for representing and operating on TextGrids produced by forced\n    aligners like FAVE or the Montreal Forced Aligner. Classes provided\n    by aligned-textgrid represent hierarchical and precedence\n    relationships among data stored in TextGrid formats allowing for\n    simplified and more accessible analysis of aligned speech data.}\n}\nFor attribution, please cite this work as:\nFruehwald, Josef, and Christian Brickhouse. 2023.\n“Aligned-Textgrid.” https://doi.org/10.5281/zenodo.10190692."
  },
  {
    "objectID": "research/papers/Fruehwald_2022_H347UNLS.html",
    "href": "research/papers/Fruehwald_2022_H347UNLS.html",
    "title": "The study of variation",
    "section": "",
    "text": "Preprint version\n\n\n\nCitationBibTeX citation:@incollection{fruehwald2022,\n  author = {Fruehwald, Josef},\n  editor = {Dresher, B Elan and Van der Hulst, Harry},\n  title = {The Study of Variation},\n  booktitle = {The Oxford History of Phonology},\n  pages = {569-590},\n  date = {2022-03-24},\n  url = {https://JoFrhwld.github.io/jofrhwld.github.io//research/papers/Fruehwald_2022_H347UNLS.html},\n  doi = {10.1093/oso/9780198796800.003.0027},\n  langid = {en},\n  abstract = {The study and formalization of intra-speaker variation\n    within variationist sociolinguistics has followed a largely parallel\n    history with generative phonology, always borrowing heavily from the\n    generative theories of the day. More recently, structured\n    probabilistic variation has become enshrined as a\n    fact-to-be-explained by any theory of human sound systems in more\n    mainstream phonology. This chapter outlines this parallel history of\n    variation study from its origins in dialectology, the evolution of\n    modern variationist sociolinguistics, and the development of more\n    contemporary variation focused phonological theory, as well as\n    critiques that have been posed over this history. The chapter\n    reviews in considerable detail how the original notion of “variable\n    rule” was elaborated and complexified, and how variation is treated\n    in constraint-based approaches. It concludes with a look towards the\n    future of variation study that is incorporating more insights from\n    psycholinguistics.}\n}\nFor attribution, please cite this work as:\nFruehwald, Josef. 2022. “The Study of Variation.” In\nThe Oxford History of Phonology, edited by B Elan Dresher and\nHarry Van der Hulst, 569–90. https://doi.org/10.1093/oso/9780198796800.003.0027."
  },
  {
    "objectID": "research/papers/Fruehwald_2019_URYFVWHE.html",
    "href": "research/papers/Fruehwald_2019_URYFVWHE.html",
    "title": "Is phonetic target uniformity phonologically, or sociolinguistically grounded?",
    "section": "",
    "text": "CitationBibTeX citation:@article{fruehwald2019,\n  author = {Fruehwald, Josef},\n  title = {Is Phonetic Target Uniformity Phonologically, or\n    Sociolinguistically Grounded?},\n  journal = {Proceedings of the 19th International Congress of Phonetic\n    Sciences, Melbourne, Australia 2019},\n  pages = {5},\n  date = {2019},\n  url = {https://www.internationalphoneticassociation.org/icphs-proceedings/ICPhS2019/papers/ICPhS_730.pdf},\n  langid = {en},\n  abstract = {In this paper, I investigate to what degree phonetic\n    uniformity in diachronic vowels shifts can be accounted for in terms\n    of a shared phonetic implementation rule of phonological features\n    {[}6, 10{]}, versus a shared social evaluation of the phonetic\n    realizations {[}19{]}. I take a particular focus on the parallel\n    fronting and subsequent retraction of the GOOSE, GOAT and MOUTH\n    vowels, as well as the raising of the preconsonantal FACE and\n    pre-voiceless PRICE vowels in Philadelphia, drawing data from the\n    Philadelphia Neighborhood Corpus {[}15{]}. Using generalized\n    additive models {[}21{]} I ﬁt models for these vowels accounting for\n    gender, date of birth, educational attainment, and vowel duration\n    using tensor product smooths. Looking at the correlation of the\n    byspeaker random intercepts, back vowel fronting appears to be\n    highly correlated, thus likely phonologically grounded, while FACE\n    and PRICE raising is not, thus likely socially grounded.}\n}\nFor attribution, please cite this work as:\nFruehwald, Josef. 2019. “Is Phonetic Target Uniformity\nPhonologically, or Sociolinguistically Grounded?” Proceedings\nof the 19th International Congress of Phonetic Sciences, Melbourne,\nAustralia 2019, 5. https://www.internationalphoneticassociation.org/icphs-proceedings/ICPhS2019/papers/ICPhS_730.pdf."
  },
  {
    "objectID": "research/papers/Fruehwald_2017_258NF56V.html",
    "href": "research/papers/Fruehwald_2017_258NF56V.html",
    "title": "Response to Berkson, Davis, & Strickler, ‘What does incipient /ay/-raising look like?’",
    "section": "",
    "text": "CitationBibTeX citation:@article{fruehwald2017,\n  author = {Fruehwald, Josef},\n  title = {Response to {Berkson,} {Davis,} \\& {Strickler,} “{What} Does\n    Incipient /Ay/-Raising Look Like?”},\n  journal = {Language},\n  volume = {93},\n  number = {3},\n  date = {2017-01},\n  url = {https://JoFrhwld.github.io/jofrhwld.github.io//research/papers/Fruehwald_2017_258NF56V.html},\n  doi = {10.1353/lan.2017.0051},\n  langid = {en},\n  abstract = {Berkson, Davis, and Strickler (2017) provide an invaluable\n    report on incipient /ay/-raising in Fort Wayne, Indiana. Their data\n    suggest that /ay/-raising conditioned strictly by phonetic\n    voice-lessness is a possible early stage in the development of\n    /ay/-raising. This raises a particularly vexing question of why\n    /ay/-raising has gone on to be conditioned by phonological voicing\n    in all North American varieties for which its interaction with /t,\n    d/ flapping has been examined. It suggests that the process of\n    phonologization reorganizes the distribution of phonetic variants,\n    rather than simply discretizing phonetic precursors.}\n}\nFor attribution, please cite this work as:\nFruehwald, Josef. 2017. “Response to Berkson, Davis, &\nStrickler, ‘What Does Incipient /Ay/-Raising Look\nLike?’” Language 93 (3). https://doi.org/10.1353/lan.2017.0051."
  },
  {
    "objectID": "research/papers/Fruehwald_2016_34D4IRNY.html",
    "href": "research/papers/Fruehwald_2016_34D4IRNY.html",
    "title": "The early influence of phonology on a phonetic change",
    "section": "",
    "text": "CitationBibTeX citation:@article{fruehwald2016,\n  author = {Fruehwald, Josef},\n  title = {The Early Influence of Phonology on a Phonetic Change},\n  journal = {Language},\n  volume = {92},\n  number = {2},\n  pages = {376-410},\n  date = {2016},\n  url = {https://muse.jhu.edu/article/621188},\n  doi = {10.1353/lan.2016.0041},\n  langid = {en},\n  abstract = {The conventional wisdom regarding the diachronic process\n    whereby phonetic phenomena become phonologized appears to be the\n    “error accumulation” model, so called by Baker, Archangeli, and\n    Mielke (2011). Under this model, biases in the phonetic context\n    result in production or perception errors, which are misapprehended\n    by listeners as target productions, and over time accumulate into\n    new target productions. In this article, I explore the predictions\n    of the hypocorrection model for one phonetic change (prevoiceless\n    /ay/-raising) in detail. I argue that properties of the phonetic\n    context underpredict and mischaracterize the contextual conditioning\n    on this phonetic change. Rather, it appears that categorical,\n    phonological conditioning is present from the very onset of this\n    change.}\n}\nFor attribution, please cite this work as:\nFruehwald, Josef. 2016. “The Early Influence of Phonology on a\nPhonetic Change.” Language 92 (2): 376–410. https://doi.org/10.1353/lan.2016.0041."
  },
  {
    "objectID": "research/papers/Fruehwald_2013_W28LR5KT.html",
    "href": "research/papers/Fruehwald_2013_W28LR5KT.html",
    "title": "Phonological Rule Change: The Constant Rate Effect",
    "section": "",
    "text": "CitationBibTeX citation:@article{fruehwald2013,\n  author = {Fruehwald, Josef and Gress Wright, Jonathan and Wallenberg,\n    Joel},\n  title = {Phonological {Rule} {Change:} {The} {Constant} {Rate}\n    {Effect}},\n  journal = {The proceedings of the North-Eastern Linguistic Society\n    (NELS)},\n  volume = {40},\n  date = {2013},\n  url = {https://JoFrhwld.github.io/jofrhwld.github.io//research/papers/Fruehwald_2013_W28LR5KT.html},\n  langid = {en},\n  abstract = {The detailed quantitative study of language change, as\n    found in studies such as Labov (1994) and Kroch (1989), has raised\n    two central questions for linguistic theory. The first is an issue\n    in the theory of language change itself, namely: do changes in\n    different components of the grammar progress in the same way? The\n    second question addresses the relationship between the study of\n    change and the development of synchronic linguistic theory: can\n    quantitative, diachronic data help to choose between alternative\n    analyses of synchronic facts? This paper addresses both of these\n    questions with the case study of the loss of word-final stop\n    fortition (frequently termed “devoicing”) in the history of German,\n    and concludes that the answer to both questions above is “yes”.}\n}\nFor attribution, please cite this work as:\nFruehwald, Josef, Jonathan Gress Wright, and Joel Wallenberg. 2013.\n“Phonological Rule Change: The Constant Rate Effect.”\nThe Proceedings of the North-Eastern Linguistic Society (NELS)\n40. https://JoFrhwld.github.io/jofrhwld.github.io//research/papers/Fruehwald_2013_W28LR5KT.html."
  },
  {
    "objectID": "research/papers/Fruehwald_2012_7HNEQZ7H.html",
    "href": "research/papers/Fruehwald_2012_7HNEQZ7H.html",
    "title": "Redevelopment of a Morphological Class",
    "section": "",
    "text": "CitationBibTeX citation:@article{fruehwald2012,\n  author = {Fruehwald, Josef},\n  editor = {Fruehwald, Josef},\n  title = {Redevelopment of a {Morphological} {Class}},\n  journal = {Penn Working Papers in Linguistics},\n  volume = {18},\n  number = {1},\n  pages = {77-86},\n  date = {2012},\n  url = {http://repository.upenn.edu/pwpl/vol18/iss1/10/},\n  langid = {en},\n  abstract = {Coronal stop deletion (or‚`TD Deletion‚`) is the paradigm\n    sociolinguistic variable. It was first described in African American\n    English (Labov et al., 1968) as a rule whereby word final /Ct/ and\n    /Cd/ clusters simplify by deleting the coronal stop. It has since\n    been found in many dialects and varieties of English. Aside from the\n    very regular phonological and phonetic factors which condition\n    whether TD Deletion applies, morphological structure also appears to\n    have an effect. The three morphological categories of primary\n    interest are (i) monomorphemes\\}, (ii) regular past tense verbs and\n    (iii) semiweak past tense verbs. In almost every dialect studied,\n    the order of morphological classes from least favoring deletion to\n    most favoring deletion is as given in (1). (1) monomorphemes\n    \\textgreater{} semiweak \\textgreater{} regular past tense In this\n    paper, I will be focusing on the difference between semiweak and\n    regular past tense. I will pursue a revised version of the analysis\n    in Guy \\& Boyd (1990), casting it in terms of Competing Grammars and\n    Distributed Morphology. Specifically, I will propose that the rate\n    of phonological TD Deletion is the same for the regular past and the\n    semiweak. What leads to higher TD Absence in the semiweak verbs is\n    variable morphological absence of /t/, i.e., there is a competing\n    morphological analysis where the past tense of keep is simply “kep”,\n    instead of “kept”.}\n}\nFor attribution, please cite this work as:\nFruehwald, Josef. 2012. “Redevelopment of a Morphological\nClass.” Edited by Josef Fruehwald. Penn Working Papers in\nLinguistics 18 (1): 77–86. http://repository.upenn.edu/pwpl/vol18/iss1/10/."
  },
  {
    "objectID": "research/papers/Fruehwald_2008_IZLBZKZV.html",
    "href": "research/papers/Fruehwald_2008_IZLBZKZV.html",
    "title": "The Spread of Raising : Opacity , Lexicalization , and Diffusion",
    "section": "",
    "text": "CitationBibTeX citation:@article{fruehwald2008,\n  author = {Fruehwald, Josef},\n  editor = {Gorman, Kyle},\n  title = {The {Spread} of {Raising} : {Opacity} , {Lexicalization} ,\n    and {Diffusion}},\n  journal = {Penn Working Papers in Linguistics},\n  volume = {14},\n  number = {2},\n  pages = {83-92},\n  date = {2008},\n  url = {http://repository.upenn.edu/pwpl/vol14/iss2/11/},\n  langid = {en},\n  abstract = {The centralization of the low upgliding diphthong\n    (typically called Canadian Raising, here just Raising), is\n    frequently cited as an example of phonological opacity. Conditioned\n    by a following voiceless segment, Raising continues to apply when an\n    underlying unstressed /t/ is flapped on the surface. Dialects which\n    have both Raising and Flapping, then, maintain the distinction\n    between “writer” and “rider” in the quality of the vowel, rather\n    than the voicing of the stop. Exceptions to the simplest formulation\n    of Raising have been reported on in the past. Underapplication of\n    Raising in pre-voiceless environments can possibly be accounted for\n    by prosodic structure (Chambers, 1973, 1989; Jensen, 2000; Vance,\n    1987). However, a few reports from the Inland North (Vance, 1987;\n    Dailey-O’Cain, 1997) and Canada (Hall, 2005) suggest that the\n    regularity of Raising’s conditioning has deteriorated, allowing\n    raised nuclei before underlyingly voiced segments. The distribution\n    of these raised variants is unpredictable within a speaker’s\n    phonology, but stable for given words, suggesting that Raising has\n    lexicalized, and is undergoing diffusion to new environments. This\n    paper focuses on the phonological status of Raising in Philadelphia.\n    Raising was identified as an incipient sound change in progress in\n    the LCV study of the 1970s, and has been revisited for study in\n    connection with its masculine association (Labov, 2001; Conn, 2005;\n    Wagner, 2007). After examining data from 12 boys, ages 14 through\n    19, it appears that Raising has lexicalized here as well.\n    {[}\\^{}y{]} frequently appears before underlyingly voiced stops, as\n    well as before nasals, but not in a phonologically predictable\n    manner. Certain words seem to be selected for consistent\n    overapplication however. “Spider” and “cider” are lexical items with\n    raised nuclei for which there is broad agreement between speakers.\n    However, there are also a number of lexical items which show more\n    interspeaker variation, such as “tiny”, produced variably as\n    {[}tayni{]} or {[}t\\^{}yni{]}. Importantly, across all of the data,\n    the effect of the lexical item on overapplication of Raising is\n    stronger and more significant than the effect of surrounding\n    phonological environment.}\n}\nFor attribution, please cite this work as:\nFruehwald, Josef. 2008. “The Spread of Raising : Opacity ,\nLexicalization , and Diffusion.” Edited by Kyle Gorman. Penn\nWorking Papers in Linguistics 14 (2): 83–92. http://repository.upenn.edu/pwpl/vol14/iss2/11/."
  },
  {
    "objectID": "research/papers/Boyd_2021_733Q4MMI.html",
    "href": "research/papers/Boyd_2021_733Q4MMI.html",
    "title": "Crosslinguistic perceptions of /s/ among English, French, and German listeners",
    "section": "",
    "text": "CitationBibTeX citation:@article{boyd2021,\n  author = {Boyd, Zac and Fruehwald, Josef and Hall-Lew, Lauren},\n  title = {Crosslinguistic Perceptions of /s/ Among {English,} {French,}\n    and {German} Listeners},\n  journal = {Language Variation and Change},\n  volume = {33},\n  number = {2},\n  pages = {165-191},\n  date = {2021-07},\n  url = {https://www.cambridge.org/core/product/identifier/S0954394521000089/type/journal_article},\n  doi = {10.1017/S0954394521000089},\n  langid = {en},\n  abstract = {This study reports the results of a crosslinguistic\n    matched guise test examining /s/ and pitch variation in judgments of\n    sexual orientation and nonnormative masculinity among English,\n    French, and German listeners. Listeners responded to /s/ and pitch\n    manipulations in native and other language stimuli (English, French,\n    German, and Estonian). All listener groups rate higher pitch guises\n    as more gay- and effeminate-sounding than lower pitch guises.\n    However, only English listeners hear {[}s+{]} guises as more gay-\n    and effeminate-sounding than {[}s{]} or {[}s−{]} guises for all\n    stimuli languages. French and German listeners do not hear {[}s+{]}\n    guises as more gay- or effeminate-sounding in any stimulus language,\n    despite this feature’s presence in native speech production. English\n    listener results show evidence of indexical transfer, when indexical\n    knowledge is applied to the perception of unknown languages. French\n    and German listener results show how the enregistered status of /s/\n    variation affects perception, despite crosslinguistic similarities\n    in production.}\n}\nFor attribution, please cite this work as:\nBoyd, Zac, Josef Fruehwald, and Lauren Hall-Lew. 2021.\n“Crosslinguistic Perceptions of /s/ Among English, French, and\nGerman Listeners.” Language Variation and Change 33 (2):\n165–91. https://doi.org/10.1017/S0954394521000089."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "I am an Assistant Professor in the Linguistics Department at the University of Kentucky. My interests within linguistics are sociolinguistics, variation and change, phonetics, and phonology.\n\nContact\n\n\n\nemail\njosef.fruehwald@uky.edu\n\n\noffice:\n1671 Patterson Office Tower"
  },
  {
    "objectID": "research/index.html",
    "href": "research/index.html",
    "title": "Research",
    "section": "",
    "text": "Generated from my Zotero publications.\n\n\n\n\n\n\n\n\n  \n    \n      2024\n    \n  \n  \n  \n    \n    aligned-textgrid: Lightweight access to structured phonetic data\n    \n      \n        with:\n      \n      \n        \n          Josef Fruehwald, Christian Brickhouse\n        \n      \n      \n      \n\n      \n\n      \n      \n        in:\n      \n      \n        \n          Poster presented at SCiL 2024\n        \n      \n      \n      \n\n      \n      \n        \n      \n      \n      \n\n        \n        \n        \n            abstract:\n        \n        \n        \n            \n            \n            \n            \n            \n        \n\n        \n        \n\n    \n    \n    aligned-textgrid: Lightweight access to structured phonetic data\n    \n      \n        with:\n      \n      \n        \n          Josef Fruehwald, Christian Brickhouse\n        \n      \n      \n      \n\n      \n\n      \n      \n        in:\n      \n      \n        \n          Proceedings of the Society for Computation in Linguistics (SCiL) 2024\n        \n      \n      \n      \n\n      \n      \n        \n      \n      \n      \n\n        \n        \n        \n            abstract:\n        \n        \n        \n            \n            \n            The goal of aligned-textgrid is to provide lightweight, scriptable access to the structured data produced by forced-aligners. The library is written in python, and currently available on the Python Package Index.\n            \n            \n        \n\n        \n        \n\n    \n    \n    \n\n  \n\n  \n    \n      2023\n    \n  \n  \n  \n    \n    fasttrackpy\n    \n      \n        with:\n      \n      \n        \n          Josef Fruehwald, Santiago Barreda\n        \n      \n      \n      \n\n      \n\n      \n      \n        \n      \n      \n      \n        version:\n      \n      \n        \n          v0.3.0\n        \n      \n      \n      \n\n      \n      \n\n        \n        \n        \n            abstract:\n        \n        \n        \n            \n            \n            This is a python implementation of the FastTrack method.\n            \n            \n        \n\n        \n        \n\n    \n    \n    aligned-textgrid\n    \n      \n        with:\n      \n      \n        \n          Josef Fruehwald, Christian Brickhouse\n        \n      \n      \n      \n\n      \n\n      \n      \n        \n      \n      \n      \n        version:\n      \n      \n        \n          v0.5.0\n        \n      \n      \n      \n\n      \n      \n\n        \n        \n        \n            abstract:\n        \n        \n        \n            \n            \n            The aligned-textgrid package provides a python interface for representing and operating on TextGrids produced by forced aligners like FAVE or the Montreal Forced Aligner. Classes provided by aligned-textgrid represent hierarchical and precedence relationships among data stored in TextGrid formats allowing for simplified and more accessible analysis of aligned speech data.\n            \n            \n        \n\n        \n        \n\n    \n    \n    fave-recode\n    \n      \n        with:\n      \n      \n        \n          Josef Fruehwald\n        \n      \n      \n      \n\n      \n\n      \n      \n        \n      \n      \n      \n        version:\n      \n      \n        \n          v0.2.0\n        \n      \n      \n      \n\n      \n      \n\n        \n        \n        \n            abstract:\n        \n        \n        \n            \n            \n            The idea behind fave-recode is that no matter how much you may adjust the dictionary of a forced-aligner, you may still want to make programmatic changes to the output.\n            \n            \n        \n\n        \n        \n\n    \n    \n    densityarea: Polygons of Bivariate Density Distributions\n    \n      \n        with:\n      \n      \n        \n          Josef Fruehwald\n        \n      \n      \n      \n\n      \n\n      \n      \n        \n      \n      \n      \n        version:\n      \n      \n        \n          v0.1.0\n        \n      \n      \n      \n\n      \n      \n\n        \n        \n        \n            abstract:\n        \n        \n        \n            \n            \n            Areas of Bivarate Density Distributions\n            \n            \n        \n\n        \n        \n\n    \n    \n    \n\n  \n\n  \n    \n      2022\n    \n  \n  \n  \n    \n    Frequency and morphological complexity in variation\n    \n      \n        with:\n      \n      \n        \n          Ruaridh Purse, Josef Fruehwald, Meredith Tamminga\n        \n      \n      \n      \n\n      \n\n      \n      \n        in:\n      \n      \n        \n          Glossa: a journal of general linguistics\n        \n      \n      \n      \n\n      \n      \n        \n      \n      \n      \n\n        \n        \n        \n            abstract:\n        \n        \n        \n            \n            \n            Broad interest in probabilistic aspects of language has reignited debates about a potential delineation between the shape of an abstract grammar and patterns of language in use. A central topic in this debate is the relationship between measures capturing aspects of language use, such as word frequency, and patterns of variation. While it has become common practice to attend to frequency measures in studies of linguistic variation, fundamental questions about exactly what linguistic unit’s frequency it is appropriate to measure in each case, and what this implies about the representations or processing mechanisms at play, remain underexplored. In the present study, we compare how three frequency measures account for variance in Coronal Stop Deletion (CSD) based on large-scale corpus data from Philadelphia English: whole-word frequency, stem frequency, and conditional (whole-word/stem) frequency. While there is an effect of all three measures on CSD outcomes in monomorphemes, the effect of conditional frequency is by far the most robust. Furthermore, only conditional frequency has an effect on CSD rates in -ed suffixed words. Thus, we suggest that frequency effects in CSD are best interpreted in terms of stem-conditional predictability of a suffix or word-edge. These results lend support to the importance of asking these fundamental questions about usage measures, and suggest that contemporary approaches to frequency should take morphological complexity into account.\n            \n            \n        \n\n        \n        \n\n    \n    \n    The study of variation\n    \n      \n        with:\n      \n      \n        \n          Josef Fruehwald\n        \n      \n      \n      \n\n      \n\n      \n      \n        in:\n      \n      \n        \n          The Oxford History of Phonology\n        \n      \n      \n      \n\n      \n      \n        \n      \n      \n      \n\n        \n        \n        \n            abstract:\n        \n        \n        \n            \n            \n            The study and formalization of intra-speaker variation within variationist sociolinguistics has followed a largely parallel history with generative phonology, always borrowing heavily from the generative theories of the day. More recently, structured probabilistic variation has become enshrined as a fact-to-be-explained by any theory of human sound systems in more mainstream phonology. This chapter outlines this parallel history of variation study from its origins in dialectology, the evolution of modern variationist sociolinguistics, and the development of more contemporary variation focused phonological theory, as well as critiques that have been posed over this history. The chapter reviews in considerable detail how the original notion of ‘variable rule’ was elaborated and complexified, and how variation is treated in constraint-based approaches. It concludes with a look towards the future of variation study that is incorporating more insights from psycholinguistics.\n            \n            \n        \n\n        \n        \n\n    \n    \n    FAVE (Forced Alignment and Vowel Extraction) Program Suite v2.0.0\n    \n      \n        with:\n      \n      \n        \n          Ingrid Rosenfelder, Josef Fruehwald, Christian Brickhouse, Keelan Evanini, Scott Seyfarth, Kyle Gorman, Hilary Prichard, Jiahong Yuan\n        \n      \n      \n      \n\n      \n\n      \n      \n        \n      \n      \n      \n        version:\n      \n      \n        \n          v2.0.0\n        \n      \n      \n      \n\n      \n      \n\n        \n        \n        \n            abstract:\n        \n        \n        \n            \n            \n            \n            \n            \n        \n\n        \n        \n\n    \n    \n    \n\n  \n\n  \n    \n      2021\n    \n  \n  \n  \n    \n    Crosslinguistic perceptions of /s/ among English, French, and German listeners\n    \n      \n        with:\n      \n      \n        \n          Zac Boyd, Josef Fruehwald, Lauren Hall-Lew\n        \n      \n      \n      \n\n      \n\n      \n      \n        in:\n      \n      \n        \n          Language Variation and Change\n        \n      \n      \n      \n\n      \n      \n        \n      \n      \n      \n\n        \n        \n        \n            abstract:\n        \n        \n        \n            \n            \n            This study reports the results of a crosslinguistic matched guise test examining /s/ and pitch variation in judgments of sexual orientation and nonnormative masculinity among English, French, and German listeners. Listeners responded to /s/ and pitch manipulations in native and other language stimuli (English, French, German, and Estonian). All listener groups rate higher pitch guises as more gay- and effeminate-sounding than lower pitch guises. However, only English listeners hear [s+] guises as more gay- and effeminate-sounding than [s] or [s−] guises for all stimuli languages. French and German listeners do not hear [s+] guises as more gay- or effeminate-sounding in any stimulus language, despite this feature’s presence in native speech production. English listener results show evidence of indexical transfer, when indexical knowledge is applied to the perception of unknown languages. French and German listener results show how the enregistered status of /s/ variation affects perception, despite crosslinguistic similarities in production.\n            \n            \n        \n\n        \n        \n\n    \n    \n    \n\n  \n\n  \n    \n      2020\n    \n  \n  \n  \n    \n    syllabifyr: v0.1.1\n    \n      \n        with:\n      \n      \n        \n          Josef Fruehwald\n        \n      \n      \n      \n\n      \n\n      \n      \n        \n      \n      \n      \n        version:\n      \n      \n        \n          v0.1.1\n        \n      \n      \n      \n\n      \n      \n\n        \n        \n        \n            abstract:\n        \n        \n        \n            \n            \n            The goal of `syllabifyr` is to provide tidy syllabification of phonetic transcriptions. So far, only CMU dict transcriptions are supported.\n            \n            \n        \n\n        \n        \n\n    \n    \n    Toward “English” Phonetics: Variability in the Pre-consonantal Voicing Effect Across English Dialects and Speakers\n    \n      \n        with:\n      \n      \n        \n          James Tanner, Morgan Sonderegger, Jane Stuart-Smith, Josef Fruehwald\n        \n      \n      \n      \n\n      \n\n      \n      \n        in:\n      \n      \n        \n          Frontiers in Artificial Intelligence\n        \n      \n      \n      \n\n      \n      \n        \n      \n      \n      \n\n        \n        \n        \n            abstract:\n        \n        \n        \n            \n            \n            Recent advances in access to spoken-language corpora and development of speech processing tools have made possible the performance of “large-scale” phonetic and sociolinguistic research. This study illustrates the usefulness of such a large-scale approach—using data from multiple corpora across a range of English dialects, collected, and analyzed with the SPADE project—to examine how the pre-consonantal Voicing Effect (longer vowels before voiced than voiceless obstruents, in e.g., bead vs. beat) is realized in spontaneous speech, and varies across dialects and individual speakers. Compared with previous reports of controlled laboratory speech, the Voicing Effect was found to be substantially smaller in spontaneous speech, but still influenced by the expected range of phonetic factors. Dialects of English differed substantially from each other in the size of the Voicing Effect, whilst individual speakers varied little relative to their particular dialect. This study demonstrates the value of large-scale phonetic research as a means of developing our understanding of the structure of speech variability, and illustrates how large-scale studies, such as those carried out within SPADE, can be applied to other questions in phonetic and sociolinguistic research.\n            \n            \n        \n\n        \n        \n\n    \n    \n    \n\n  \n\n  \n    \n      2019\n    \n  \n  \n  \n    \n    Using the Tolerance Principle to predict phonological change\n    \n      \n        with:\n      \n      \n        \n          Betsy Sneller, Josef Fruehwald, Charles Yang\n        \n      \n      \n      \n\n      \n\n      \n      \n        in:\n      \n      \n        \n          Language Variation and Change\n        \n      \n      \n      \n\n      \n      \n        \n      \n      \n      \n\n        \n        \n        \n            abstract:\n        \n        \n        \n            \n            \n            Language acquisition is a well-established avenue for language change (Labov, 2007). Given the theoretical importance of language acquisition to language change, it is all the more important to formulate clear theories of transmission-based change. In this paper, we provide a simulation method designed to test the plausibility of different possible transmission-based changes, using the Tolerance Principle (Yang, 2016) to determine precise points at which different possible changes may become plausible for children acquiring language. We apply this method to a case study of a complex change currently in progress: the allophonic restructuring of /æ/ in Philadelphia English. Using this model, we are able to evaluate several competing explanations of the ongoing change and determine that the allophonic restructuring of /æ/ in Philadelphia English is mostly likely the result of children acquiring language from mixed dialect input, consisting of approximately 40% input from speakers with a nasal /æ/ split. We show that applying our simulation to a phonological change allows us to make precise quantitative predications about the progress of this change. Moreover, it forces us to reassess intuitively plausible hypotheses about language change, such as grammatical simplification, in a quantitative and independently motivated framework of acquisition.\n            \n            \n        \n\n        \n        \n\n    \n    \n    Is phonetic target uniformity phonologically, or sociolinguistically grounded?\n    \n      \n        with:\n      \n      \n        \n          Josef Fruehwald\n        \n      \n      \n      \n\n      \n\n      \n      \n        in:\n      \n      \n        \n          Proceedings of the 19th International Congress of Phonetic Sciences, Melbourne, Australia 2019\n        \n      \n      \n      \n\n      \n      \n        \n      \n      \n      \n\n        \n        \n        \n            abstract:\n        \n        \n        \n            \n            \n            In this paper, I investigate to what degree phonetic uniformity in diachronic vowels shifts can be accounted for in terms of a shared phonetic implementation rule of phonological features [6, 10], versus a shared social evaluation of the phonetic realizations [19]. I take a particular focus on the parallel fronting and subsequent retraction of the GOOSE, GOAT and MOUTH vowels, as well as the raising of the preconsonantal FACE and pre-voiceless PRICE vowels in Philadelphia, drawing data from the Philadelphia Neighborhood Corpus [15]. Using generalized additive models [21] I ﬁt models for these vowels accounting for gender, date of birth, educational attainment, and vowel duration using tensor product smooths. Looking at the correlation of the byspeaker random intercepts, back vowel fronting appears to be highly correlated, thus likely phonologically grounded, while FACE and PRICE raising is not, thus likely socially grounded.\n            \n            \n        \n\n        \n        \n\n    \n    \n    Age vectors vs. axes of intraspeaker variation in vowel formants measured automatically from several English speech corpora.\n    \n      \n        with:\n      \n      \n        \n          Jeff Mielke, Erik R Thomas, Josef Fruehwald, Michael McAuliffe, Morgan Sonderegger, Jane Stuart-Smith, Robin Dodsworth\n        \n      \n      \n      \n\n      \n\n      \n      \n        in:\n      \n      \n        \n          Proceedings of the 19th International Congress of Phonetic Sciences, Melbourne, Australia 2019\n        \n      \n      \n      \n\n      \n      \n        \n      \n      \n      \n\n        \n        \n        \n            abstract:\n        \n        \n        \n            \n            \n            To test the hypothesis that intraspeaker variation in vowel formants is related to the direction of diachronic change, we compare the direction of change in apparent time with the axis of intraspeaker variation in F1 and F2 for vowel phonemes in several corpora of North American and Scottish English. These vowels were measured automatically with a scheme (tested on hand-measured vowels) that considers the frequency, bandwidth, and amplitude of the ﬁrst three formants in reference to a prototype. In the corpus data, we ﬁnd that the axis of intraspeaker variation is typically aligned vertically, presumably corresponding to the degree of jaw opening for individual tokens, but for the North American GOOSE vowel, the axis of intraspeaker variation is aligned with the (horizontal) axis of diachronic change for this vowel across North America. This may help to explain why fronting and unrounding of high back vowels are common shifts across languages.\n            \n            \n        \n\n        \n        \n\n    \n    \n    \n\n  \n\n  \n    \n      2017\n    \n  \n  \n  \n    \n    Response to Berkson, Davis, & Strickler, ‘What does incipient /ay/-raising look like?’\n    \n      \n        with:\n      \n      \n        \n          Josef Fruehwald\n        \n      \n      \n      \n\n      \n\n      \n      \n        in:\n      \n      \n        \n          Language\n        \n      \n      \n      \n\n      \n      \n        \n      \n      \n      \n\n        \n        \n        \n            abstract:\n        \n        \n        \n            \n            \n            Berkson, Davis, and Strickler (2017) provide an invaluable report on incipient /ay/-raising in Fort Wayne, Indiana. Their data suggest that /ay/-raising conditioned strictly by phonetic voice-lessness is a possible early stage in the development of /ay/-raising. This raises a particularly vexing question of why /ay/-raising has gone on to be conditioned by phonological voicing in all North American varieties for which its interaction with /t, d/ flapping has been examined. It suggests that the process of phonologization reorganizes the distribution of phonetic variants, rather than simply discretizing phonetic precursors.\n            \n            \n        \n\n        \n        \n\n    \n    \n    Generations, lifespans, and the zeitgeist\n    \n      \n        with:\n      \n      \n        \n          Josef Fruehwald\n        \n      \n      \n      \n\n      \n\n      \n      \n        in:\n      \n      \n        \n          Language Variation and Change\n        \n      \n      \n      \n\n      \n      \n        \n      \n      \n      \n\n        \n        \n        \n            abstract:\n        \n        \n        \n            \n            \n            This paper is equal parts methodological recommendation and an empirical investigation of the time dimensions of linguistic change. It is increasingly common in the sociolinguistic literature for researchers to utilize speech data that was collected over the course of many decades. These kinds of datasets contain three different time dimensions that researchers can utilize to investigate language change: (i) the speakers' dates of birth, (ii) the speakers' ages at the time of the recording, and (iii) the date of the recording. Proper investigation of all three time dimensions is crucial for a theoretical understanding of the dynamics of language change. I recommend utilizing two-dimensional tensor product smooths, fit over speakers' date of birth and the year of the recording, to analyze the contribution of these three time dimensions to linguistic changes. I apply this method to five language changes, based on data drawn from the Philadelphia Neighborhood Corpus. I find relatively weak evidence for lifespan effects in these changes, robust generational effects, and in one case, evidence of a zeitgeist effect.\n            \n            \n        \n\n        \n        \n\n    \n    \n    \n\n  \n\n  \n    \n      2016\n    \n  \n  \n  \n    \n    The early influence of phonology on a phonetic change\n    \n      \n        with:\n      \n      \n        \n          Josef Fruehwald\n        \n      \n      \n      \n\n      \n\n      \n      \n        in:\n      \n      \n        \n          Language\n        \n      \n      \n      \n\n      \n      \n        \n      \n      \n      \n\n        \n        \n        \n            abstract:\n        \n        \n        \n            \n            \n            The conventional wisdom regarding the diachronic process whereby phonetic phenomena become phonologized appears to be the ‘error accumulation’ model, so called by Baker, Archangeli, and Mielke (2011). Under this model, biases in the phonetic context result in production or perception errors, which are misapprehended by listeners as target productions, and over time accumulate into new target productions. In this article, I explore the predictions of the hypocorrection model for one phonetic change (prevoiceless /ay/-raising) in detail. I argue that properties of the phonetic context underpredict and mischaracterize the contextual conditioning on this phonetic change. Rather, it appears that categorical, phonological conditioning is present from the very onset of this change.\n            \n            \n        \n\n        \n        \n\n    \n    \n    Filled Pause Choice as a Sociolinguistic Variable\n    \n      \n        with:\n      \n      \n        \n          Josef Fruehwald\n        \n      \n      \n      \n\n      \n\n      \n      \n        in:\n      \n      \n        \n          U. Penn Working Papers in Linguistics\n        \n      \n      \n      \n\n      \n      \n        \n      \n      \n      \n\n        \n        \n        \n            abstract:\n        \n        \n        \n            \n            \n            In this paper, I argue that filled pause selection (um/uh) is a sociolinguistic variable, conditioned by both internal and external factors. There appears to be a language change in progress towards selecting um more often than uh. In all respects, the (UHM) variable appears to pattern quantiatively just like all other sociolinguistic variables which have been examined, even though the locus of (UHM) variation would seem to be firmly in the speech planning domain. Combined with the quantitative systematicity of sociolinguistic variables across the full range of linguistic modules, I argue that the locus of variation may not be in the grammar, but rather constitutes a separate domain of knowledge, perhaps what Preston (2004) called the “sociocultural selection device.”\n            \n            \n        \n\n        \n        \n\n    \n    \n    Variation and Change in the Use of Hesitation Markers in Germanic Languages\n    \n      \n        with:\n      \n      \n        \n          Martijn Wieling, Jack Grieve, Gosse Bouma, Josef Fruehwald, John Coleman, M. Liberman\n        \n      \n      \n      \n\n      \n\n      \n      \n        in:\n      \n      \n        \n          Language Dynamics and Change\n        \n      \n      \n      \n\n      \n      \n        \n      \n      \n      \n\n        \n        \n        \n            abstract:\n        \n        \n        \n            \n            \n            In this study, we investigate crosslinguistic patterns in the alternation between um, a hesitation marker consisting of a neutral vowel followed by a final labial nasal, and uh, a hesitation marker consisting of a neutral vowel in an open syllable. Based on a quantitative analysis of a range of spoken and written corpora, we identify clear and consistent patterns of change in the use of these forms in various Germanic languages (English, Dutch, German, Norwegian, Danish, Faroese) and dialects (American English, British English), with the use of um increasing over time relative to the use of uh. We also find that this pattern of change is generally led by women and more educated speakers. Finally, we propose a series of possible explanations for this surprising change in hesitation marker usage that is currently taking place across Germanic languages.\n            \n            \n        \n\n        \n        \n\n    \n    \n    \n\n  \n\n  \n    \n      2015\n    \n  \n  \n  \n    \n    I’m done my homework—Case assignment in a stative passive\n    \n      \n        with:\n      \n      \n        \n          Josef Fruehwald, Neil Myler\n        \n      \n      \n      \n\n      \n\n      \n      \n        in:\n      \n      \n        \n          Linguistic Variation\n        \n      \n      \n      \n\n      \n      \n        \n      \n      \n      \n\n        \n        \n        \n            abstract:\n        \n        \n        \n            \n            \n            We present an analysis of an understudied construction found in Philadelphian and Canadian English, and also in certain Vermont varieties. In this construction, the participle of certain verbs can appear along with a form of the verb be and a DP complement, producing strings like I’m done my homework , I’m finished my fries , and (in Vermont) I’m started the project . We show that the participle in the construction is an adjectival passive, not a perfect construction. We further argue that the internal argument DP in the construction is receiving Case from the adjectival head a , similar to what happens in all English dialects with the adjective worth , and that the internal argument is interpreted via a mechanism of complement coercion. The microparametric variation we find across English dialects with respect to the availability of this construction is accounted for by variation in the selectional restrictions on the a head.\n            \n            \n        \n\n        \n        \n\n    \n    \n    FAVE (Forced Alignment and Vowel Extraction) 1.2.2\n    \n      \n        with:\n      \n      \n        \n          Ingrid Rosenfelder, Josef Fruehwald, Keelan Evanini, Scott Seyfarth, Kyle Gorman, Hilary Prichard, Jiahong Yuan\n        \n      \n      \n      \n\n      \n\n      \n      \n        \n      \n      \n      \n        version:\n      \n      \n        \n          v1.2.2\n        \n      \n      \n      \n\n      \n      \n\n        \n        \n        \n            abstract:\n        \n        \n        \n            \n            \n            \n            \n            \n        \n\n        \n        \n\n    \n    \n    \n\n  \n\n  \n    \n      2013\n    \n  \n  \n  \n    \n    The Phonological Influence on Phonetic Change\n    \n      \n        with:\n      \n      \n        \n          Josef Fruehwald\n        \n      \n      \n      \n\n      \n\n      \n      \n        in:\n      \n      \n        \n          \n        \n      \n      \n      \n\n      \n      \n        \n      \n      \n      \n\n        \n        \n        \n            abstract:\n        \n        \n        \n            \n            \n            This dissertation addresses the broad question about how phonology and phonetics are interre- lated, specifically how phonetic language changes, which gradually alter the phonetics of speech sounds, affect the phonological system of the language, and vice versa. Some questions I address are: (i) What aspects of speakers’ knowledge of their language are changing during a phonetic change? (ii) What is the relative timing of a phonetic change and phonological reanalysis? (iii) Can a modular feed-forward model of phonology and phonetics account of the observed patterns of phonetic change? (iv) What are the consequences of my results for theories of phonology, phonetics, and language acquisition? (v) What unique insight into the answers to these questions can the study of language change in progress give us over other methodologies? To address these questions, I drew data from the Philadelphia Neighborhood Corpus [PNC] (Labov and Rosenfelder, 2011), a collection of sociolinguistic interviews carried out between 1973 and 2013. Using the PNC data, I utilized a number of different statistical modeling techniques to evaluate models of phonetic change and phonologization, including standard mixed effects re- gression modeling in R (Bates, 2006), and hierarchical Bayesian modeling via Hamiltonian Monte Carlo in Stan (Stan Development Team, 2012). My results are challenging to the conventional wisdom that phonologization is a late-stage reanalysis of phonetic coarticulatory and perceptual effects (e.g. Ohala, 1981). Rather, it appears that phonologization occurs simultaneously with the onset of phonetic changes. I arrive at this conclusion by examining the rate of change of contextual vowel variants, and by investigating mismatches between which variants are expected to change on phonetic grounds versus phono- logical grounds. In my analysis, not only can a modular feed-forward model of phonology and phonetics account for observed patterns of phonetic change, but must be appealed to in some cases. These results revise some the facts to be explained by diachronic phonology, and I suggest the question to be pursued ought to be how phonological innovations happen when there are relatively small phonetic precursors.\n            \n            \n        \n\n        \n        \n\n    \n    \n    Phonological Rule Change: The Constant Rate Effect\n    \n      \n        with:\n      \n      \n        \n          Josef Fruehwald, Jonathan Gress Wright, Joel Wallenberg\n        \n      \n      \n      \n\n      \n\n      \n      \n        in:\n      \n      \n        \n          The proceedings of the North-Eastern Linguistic Society (NELS)\n        \n      \n      \n      \n\n      \n      \n        \n      \n      \n      \n\n        \n        \n        \n            abstract:\n        \n        \n        \n            \n            \n            The detailed quantitative study of language change, as found in studies such as Labov (1994) and Kroch (1989), has raised two central questions for linguistic theory. The first is an issue in the theory of language change itself, namely: do changes in different components of the grammar progress in the same way? The second question addresses the relationship between the study of change and the development of synchronic linguistic theory: can quantitative, diachronic data help to choose between alternative analyses of synchronic facts? This paper addresses both of these questions with the case study of the loss of word-final stop fortition (frequently termed \"devoicing\") in the history of German, and concludes that the answer to both questions above is \"yes\".\n            \n            \n        \n\n        \n        \n\n    \n    \n    One hundred years of sound change in Philadelphia: Linear Incrementaion, Reversal, and Reanalysis\n    \n      \n        with:\n      \n      \n        \n          William Labov, Ingrid Rosenfelder, Josef Fruehwald\n        \n      \n      \n      \n\n      \n\n      \n      \n        in:\n      \n      \n        \n          Language\n        \n      \n      \n      \n\n      \n      \n        \n      \n      \n      \n\n        \n        \n        \n            abstract:\n        \n        \n        \n            \n            \n            The study of sound change in progress in Philadelphia has been facilitated by the application of forced alignment and automatic vowel measurement to a large corpus of neighborhood studies, including 379 speakers with dates of birth from 1888 to 1991. Two of the sound changes active in the 1970s show a linear pattern of incrementation in succeeding decades. The fronting of back upgliding vowels /aw/ and /ow/ shows a reversal in the direction of change, beginning with those born after 1940. The study also finds a general withdrawal from two salient features of local phonology, tense /æh/ and /oh/, led by those with higher education. Younger speakers with higher education have also reorganized the traditional Philadelphia tense/lax split of short-a to form a nasal system with tensing before all and only nasal consonants. The development of the Philadelphia vowel system can be understood in the geographic context of neighboring dialects. Features in common with North and North Midland dialects have accelerated in use while features in common with South Midland and Southern dialects have been reversed in favor of Northern patterns. The microevolution of a linguistic system can be seen here as subject to phonological generalizations but driven by social evaluation as features rise in level of salience for members of the speech community.\n            \n            \n        \n\n        \n        \n\n    \n    \n    \n\n  \n\n  \n    \n      2012\n    \n  \n  \n  \n    \n    Redevelopment of a Morphological Class\n    \n      \n        with:\n      \n      \n        \n          Josef Fruehwald\n        \n      \n      \n      \n\n      \n\n      \n      \n        in:\n      \n      \n        \n          Penn Working Papers in Linguistics\n        \n      \n      \n      \n\n      \n      \n        \n      \n      \n      \n\n        \n        \n        \n            abstract:\n        \n        \n        \n            \n            \n            Coronal stop deletion (or‚`TD Deletion‚`) is the paradigm sociolinguistic variable. It was first described in African American English (Labov et al., 1968) as a rule whereby word final /Ct/ and /Cd/ clusters simplify by deleting the coronal stop. It has since been found in many dialects and varieties of English. Aside from the very regular phonological and phonetic factors which condition whether TD Deletion applies, morphological structure also appears to have an effect. The three morphological categories of primary interest are (i) monomorphemes}, (ii) regular past tense verbs and (iii) semiweak past tense verbs.\nIn almost every dialect studied, the order of morphological classes from least favoring deletion to most favoring deletion is as given in (1).\n(1) monomorphemes &gt; semiweak &gt; regular past tense\nIn this paper, I will be focusing on the difference between semiweak and regular past tense. I will pursue a revised version of the analysis in Guy & Boyd (1990), casting it in terms of Competing Grammars and Distributed Morphology. Specifically, I will propose that the rate of phonological TD Deletion is the same for the regular past and the semiweak. What leads to higher TD Absence in the semiweak verbs is variable morphological absence of /t/, i.e., there is a competing morphological analysis where the past tense of keep is simply \"kep\", instead of \"kept\".\n            \n            \n        \n\n        \n        \n\n    \n    \n    \n\n  \n\n  \n    \n      2011\n    \n  \n  \n  \n    \n    Cross-derivational feeding is epiphenomenal\n    \n      \n        with:\n      \n      \n        \n          Josef Fruehwald, Kyle Gorman\n        \n      \n      \n      \n\n      \n\n      \n      \n        in:\n      \n      \n        \n          Studies in the Linguistic Sciences: Illinois Working Papers\n        \n      \n      \n      \n\n      \n      \n        \n      \n      \n      \n\n        \n        \n        \n            abstract:\n        \n        \n        \n            \n            \n            Baković (2005) proposes that patterns of sufficiently-similar segment avoidance are the result of interacting agreement and antigemination constraints, a pattern known as cross-derivational feeding (CDF). The bleeding interactions between epenthesis and assimilation which prevent adjacent sufficiently-similar segments in English are shown to follow, however, from extragrammatical considerations. Several case studies provide evidence against the major predictions of CDF.\n            \n            \n        \n\n        \n        \n\n    \n    \n    FAVE (Forced Alignment and Vowel Extraction) Program Suite.\n    \n      \n        with:\n      \n      \n        \n          Ingrid Rosenfelder, Josef Fruehwald, Keelan Evanini, Jiahong Yuan\n        \n      \n      \n      \n\n      \n\n      \n      \n        \n      \n      \n      \n        version:\n      \n      \n        \n          v0.0.0\n        \n      \n      \n      \n\n      \n      \n\n        \n        \n        \n            abstract:\n        \n        \n        \n            \n            \n            \n            \n            \n        \n\n        \n        \n\n    \n    \n    \n\n  \n\n  \n    \n      2008\n    \n  \n  \n  \n    \n    The Spread of Raising : Opacity , Lexicalization , and Diffusion\n    \n      \n        with:\n      \n      \n        \n          Josef Fruehwald\n        \n      \n      \n      \n\n      \n\n      \n      \n        in:\n      \n      \n        \n          Penn Working Papers in Linguistics\n        \n      \n      \n      \n\n      \n      \n        \n      \n      \n      \n\n        \n        \n        \n            abstract:\n        \n        \n        \n            \n            \n            The centralization of the low upgliding diphthong (typically called Canadian Raising, here just Raising), is frequently cited as an example of phonological opacity. Conditioned by a following voiceless segment, Raising continues to apply when an underlying unstressed /t/ is flapped on the surface. Dialects which have both Raising and Flapping, then, maintain the distinction between \"writer\" and \"rider\" in the quality of the vowel, rather than the voicing of the stop. Exceptions to the simplest formulation of Raising have been reported on in the past. Underapplication of Raising in pre-voiceless environments can possibly be accounted for by prosodic structure (Chambers, 1973, 1989; Jensen, 2000; Vance, 1987). However, a few reports from the Inland North (Vance, 1987; Dailey-O'Cain, 1997) and Canada (Hall, 2005) suggest that the regularity of Raising's conditioning has deteriorated, allowing raised nuclei before underlyingly voiced segments. The distribution of these raised variants is unpredictable within a speaker's phonology, but stable for given words, suggesting that Raising has lexicalized, and is undergoing diffusion to new environments. This paper focuses on the phonological status of Raising in Philadelphia. Raising was identified as an incipient sound change in progress in the LCV study of the 1970s, and has been revisited for study in connection with its masculine association (Labov, 2001; Conn, 2005; Wagner, 2007). After examining data from 12 boys, ages 14 through 19, it appears that Raising has lexicalized here as well. [^y] frequently appears before underlyingly voiced stops, as well as before nasals, but not in a phonologically predictable manner. Certain words seem to be selected for consistent overapplication however. \"Spider\" and \"cider\" are lexical items with raised nuclei for which there is broad agreement between speakers. However, there are also a number of lexical items which show more interspeaker variation, such as \"tiny\", produced variably as [tayni] or [t^yni]. Importantly, across all of the data, the effect of the lexical item on overapplication of Raising is stronger and more significant than the effect of surrounding phonological environment.\n            \n            \n        \n\n        \n        \n\n    \n    \n    \n\n  \n\n  \n    \n      2007\n    \n  \n  \n  \n    \n    The Spread of Raising: Opacity, lexicalization, and diffusion\n    \n      \n        with:\n      \n      \n        \n          Josef Fruehwald\n        \n      \n      \n      \n\n      \n\n      \n      \n        in:\n      \n      \n        \n          College Undergraduate Research Electronic Journal\n        \n      \n      \n      \n\n      \n      \n        \n      \n      \n      \n\n        \n        \n        \n            abstract:\n        \n        \n        \n            \n            \n            Canadian Raising is typically described as the centralization of the nucleus of /ay/ before voiceless segments. However some recent studies in areas affected by Raising have shown that the current conditioning factors are not as regular as reported previously (Vance, 1987; Dailey-O’Cain, 1997; Hall, 2005). This paper explores the status of Raising in Philadelphia. Examining data from 12 boys, ages 14 to 19, it appears that Raising has lexicalized here as well. While Raising occurs before a number of voiced stops and nasals, the words which experience Raising most regularly suggest that it has spread due to its opaque applications.\n            \n            \n        \n\n        \n        \n\n    \n    \n    \n\n  \n\n\n\nNo matching items",
    "crumbs": [
      "Research"
    ]
  },
  {
    "objectID": "research/papers/Fruehwald_2007_MG8DFJEK.html",
    "href": "research/papers/Fruehwald_2007_MG8DFJEK.html",
    "title": "The Spread of Raising: Opacity, lexicalization, and diffusion",
    "section": "",
    "text": "CitationBibTeX citation:@article{fruehwald2007,\n  author = {Fruehwald, Josef},\n  title = {The {Spread} of {Raising:} {Opacity,} Lexicalization, and\n    Diffusion},\n  journal = {College Undergraduate Research Electronic Journal},\n  date = {2007},\n  url = {http://repository.upenn.edu/curej/73},\n  langid = {en},\n  abstract = {Canadian Raising is typically described as the\n    centralization of the nucleus of /ay/ before voiceless segments.\n    However some recent studies in areas affected by Raising have shown\n    that the current conditioning factors are not as regular as reported\n    previously (Vance, 1987; Dailey-O’Cain, 1997; Hall, 2005). This\n    paper explores the status of Raising in Philadelphia. Examining data\n    from 12 boys, ages 14 to 19, it appears that Raising has lexicalized\n    here as well. While Raising occurs before a number of voiced stops\n    and nasals, the words which experience Raising most regularly\n    suggest that it has spread due to its opaque applications.}\n}\nFor attribution, please cite this work as:\nFruehwald, Josef. 2007. “The Spread of Raising: Opacity,\nLexicalization, and Diffusion.” College Undergraduate\nResearch Electronic Journal. http://repository.upenn.edu/curej/73."
  },
  {
    "objectID": "research/papers/Fruehwald_2011_LPQN5R3M.html",
    "href": "research/papers/Fruehwald_2011_LPQN5R3M.html",
    "title": "Cross-derivational feeding is epiphenomenal",
    "section": "",
    "text": "CitationBibTeX citation:@article{fruehwald2011,\n  author = {Fruehwald, Josef and Gorman, Kyle},\n  title = {Cross-Derivational Feeding Is Epiphenomenal},\n  journal = {Studies in the Linguistic Sciences: Illinois Working\n    Papers},\n  pages = {36-50},\n  date = {2011},\n  url = {https://www.ideals.illinois.edu/handle/2142/25512},\n  langid = {en},\n  abstract = {Baković (2005) proposes that patterns of\n    sufficiently-similar segment avoidance are the result of interacting\n    agreement and antigemination constraints, a pattern known as\n    cross-derivational feeding (CDF). The bleeding interactions between\n    epenthesis and assimilation which prevent adjacent\n    sufficiently-similar segments in English are shown to follow,\n    however, from extragrammatical considerations. Several case studies\n    provide evidence against the major predictions of CDF.}\n}\nFor attribution, please cite this work as:\nFruehwald, Josef, and Kyle Gorman. 2011. “Cross-Derivational\nFeeding Is Epiphenomenal.” Studies in the Linguistic\nSciences: Illinois Working Papers, 36–50. https://www.ideals.illinois.edu/handle/2142/25512."
  },
  {
    "objectID": "research/papers/Fruehwald_2013_H3BZPAT7.html",
    "href": "research/papers/Fruehwald_2013_H3BZPAT7.html",
    "title": "The Phonological Influence on Phonetic Change",
    "section": "",
    "text": "CitationBibTeX citation:@phdthesis{fruehwald2013,\n  author = {Fruehwald, Josef},\n  title = {The {Phonological} {Influence} on {Phonetic} {Change}},\n  date = {2013},\n  url = {https://JoFrhwld.github.io/jofrhwld.github.io//research/papers/Fruehwald_2013_H3BZPAT7.html},\n  langid = {en},\n  abstract = {This dissertation addresses the broad question about how\n    phonology and phonetics are interre- lated, specifically how\n    phonetic language changes, which gradually alter the phonetics of\n    speech sounds, affect the phonological system of the language, and\n    vice versa. Some questions I address are: (i) What aspects of\n    speakers’ knowledge of their language are changing during a phonetic\n    change? (ii) What is the relative timing of a phonetic change and\n    phonological reanalysis? (iii) Can a modular feed-forward model of\n    phonology and phonetics account of the observed patterns of phonetic\n    change? (iv) What are the consequences of my results for theories of\n    phonology, phonetics, and language acquisition? (v) What unique\n    insight into the answers to these questions can the study of\n    language change in progress give us over other methodologies? To\n    address these questions, I drew data from the Philadelphia\n    Neighborhood Corpus {[}PNC{]} (Labov and Rosenfelder, 2011), a\n    collection of sociolinguistic interviews carried out between 1973\n    and 2013. Using the PNC data, I utilized a number of different\n    statistical modeling techniques to evaluate models of phonetic\n    change and phonologization, including standard mixed effects re-\n    gression modeling in R (Bates, 2006), and hierarchical Bayesian\n    modeling via Hamiltonian Monte Carlo in Stan (Stan Development Team,\n    2012). My results are challenging to the conventional wisdom that\n    phonologization is a late-stage reanalysis of phonetic\n    coarticulatory and perceptual effects (e.g. Ohala, 1981). Rather, it\n    appears that phonologization occurs simultaneously with the onset of\n    phonetic changes. I arrive at this conclusion by examining the rate\n    of change of contextual vowel variants, and by investigating\n    mismatches between which variants are expected to change on phonetic\n    grounds versus phono- logical grounds. In my analysis, not only can\n    a modular feed-forward model of phonology and phonetics account for\n    observed patterns of phonetic change, but must be appealed to in\n    some cases. These results revise some the facts to be explained by\n    diachronic phonology, and I suggest the question to be pursued ought\n    to be how phonological innovations happen when there are relatively\n    small phonetic precursors.}\n}\nFor attribution, please cite this work as:\nFruehwald, Josef. 2013. “The Phonological Influence on Phonetic\nChange.” https://JoFrhwld.github.io/jofrhwld.github.io//research/papers/Fruehwald_2013_H3BZPAT7.html."
  },
  {
    "objectID": "research/papers/Fruehwald_2015_TJI9T9W6.html",
    "href": "research/papers/Fruehwald_2015_TJI9T9W6.html",
    "title": "I’m done my homework—Case assignment in a stative passive",
    "section": "",
    "text": "CitationBibTeX citation:@article{fruehwald2015,\n  author = {Fruehwald, Josef and Myler, Neil},\n  title = {I’m Done My {homework—Case} Assignment in a Stative Passive},\n  journal = {Linguistic Variation},\n  volume = {15},\n  number = {2},\n  pages = {141-168},\n  date = {2015},\n  url = {http://www.jbe-platform.com/content/journals/10.1075/lv.15.2.01fru},\n  doi = {10.1075/lv.15.2.01fru},\n  langid = {en},\n  abstract = {We present an analysis of an understudied construction\n    found in Philadelphian and Canadian English, and also in certain\n    Vermont varieties. In this construction, the participle of certain\n    verbs can appear along with a form of the verb be and a DP\n    complement, producing strings like I’m done my homework , I’m\n    finished my fries , and (in Vermont) I’m started the project . We\n    show that the participle in the construction is an adjectival\n    passive, not a perfect construction. We further argue that the\n    internal argument DP in the construction is receiving Case from the\n    adjectival head a , similar to what happens in all English dialects\n    with the adjective worth , and that the internal argument is\n    interpreted via a mechanism of complement coercion. The\n    microparametric variation we find across English dialects with\n    respect to the availability of this construction is accounted for by\n    variation in the selectional restrictions on the a head.}\n}\nFor attribution, please cite this work as:\nFruehwald, Josef, and Neil Myler. 2015. “I’m Done My Homework—Case\nAssignment in a Stative Passive.” Linguistic Variation\n15 (2): 141–68. https://doi.org/10.1075/lv.15.2.01fru."
  },
  {
    "objectID": "research/papers/Fruehwald_2016_TCTQU8FS.html",
    "href": "research/papers/Fruehwald_2016_TCTQU8FS.html",
    "title": "Filled Pause Choice as a Sociolinguistic Variable",
    "section": "",
    "text": "CitationBibTeX citation:@article{fruehwald2016,\n  author = {Fruehwald, Josef},\n  title = {Filled {Pause} {Choice} as a {Sociolinguistic} {Variable}},\n  journal = {U. Penn Working Papers in Linguistics},\n  volume = {22},\n  number = {2},\n  pages = {41-49},\n  date = {2016},\n  url = {https://repository.upenn.edu/pwpl/vol22/iss2/6/},\n  langid = {en},\n  abstract = {In this paper, I argue that filled pause selection (um/uh)\n    is a sociolinguistic variable, conditioned by both internal and\n    external factors. There appears to be a language change in progress\n    towards selecting um more often than uh. In all respects, the (UHM)\n    variable appears to pattern quantiatively just like all other\n    sociolinguistic variables which have been examined, even though the\n    locus of (UHM) variation would seem to be firmly in the speech\n    planning domain. Combined with the quantitative systematicity of\n    sociolinguistic variables across the full range of linguistic\n    modules, I argue that the locus of variation may not be in the\n    grammar, but rather constitutes a separate domain of knowledge,\n    perhaps what Preston (2004) called the “sociocultural selection\n    device.”}\n}\nFor attribution, please cite this work as:\nFruehwald, Josef. 2016. “Filled Pause Choice as a Sociolinguistic\nVariable.” U. Penn Working Papers in Linguistics 22 (2):\n41–49. https://repository.upenn.edu/pwpl/vol22/iss2/6/."
  },
  {
    "objectID": "research/papers/Fruehwald_2017_ETG527QQ.html",
    "href": "research/papers/Fruehwald_2017_ETG527QQ.html",
    "title": "Generations, lifespans, and the zeitgeist",
    "section": "",
    "text": "CitationBibTeX citation:@article{fruehwald2017,\n  author = {Fruehwald, Josef},\n  title = {Generations, Lifespans, and the Zeitgeist},\n  journal = {Language Variation and Change},\n  volume = {29},\n  number = {1},\n  pages = {1-27},\n  date = {2017},\n  url = {https://www.cambridge.org/core/product/identifier/S0954394517000060/type/journal_article},\n  doi = {10.1017/S0954394517000060},\n  langid = {en},\n  abstract = {This paper is equal parts methodological recommendation\n    and an empirical investigation of the time dimensions of linguistic\n    change. It is increasingly common in the sociolinguistic literature\n    for researchers to utilize speech data that was collected over the\n    course of many decades. These kinds of datasets contain three\n    different time dimensions that researchers can utilize to\n    investigate language change: (i) the speakers’ dates of birth, (ii)\n    the speakers’ ages at the time of the recording, and (iii) the date\n    of the recording. Proper investigation of all three time dimensions\n    is crucial for a theoretical understanding of the dynamics of\n    language change. I recommend utilizing two-dimensional tensor\n    product smooths, fit over speakers’ date of birth and the year of\n    the recording, to analyze the contribution of these three time\n    dimensions to linguistic changes. I apply this method to five\n    language changes, based on data drawn from the Philadelphia\n    Neighborhood Corpus. I find relatively weak evidence for lifespan\n    effects in these changes, robust generational effects, and in one\n    case, evidence of a zeitgeist effect.}\n}\nFor attribution, please cite this work as:\nFruehwald, Josef. 2017. “Generations, Lifespans, and the\nZeitgeist.” Language Variation and Change 29 (1): 1–27.\nhttps://doi.org/10.1017/S0954394517000060."
  },
  {
    "objectID": "research/papers/Fruehwald_2020_6IQH5VV5.html",
    "href": "research/papers/Fruehwald_2020_6IQH5VV5.html",
    "title": "syllabifyr: v0.1.1",
    "section": "",
    "text": "CitationBibTeX citation:@software{fruehwald2020,\n  author = {Fruehwald, Josef},\n  title = {Syllabifyr: V0.1.1},\n  version = {v0.1.1},\n  date = {2020-10-24},\n  url = {https://jofrhwld.github.io/syllabifyr/},\n  doi = {10.5281/zenodo.10393038},\n  langid = {en},\n  abstract = {The goal of `syllabifyr` is to provide tidy\n    syllabification of phonetic transcriptions. So far, only CMU dict\n    transcriptions are supported.}\n}\nFor attribution, please cite this work as:\nFruehwald, Josef. 2020. “Syllabifyr: V0.1.1.” https://doi.org/10.5281/zenodo.10393038."
  },
  {
    "objectID": "research/papers/Fruehwald_2023_BNWT43F9.html",
    "href": "research/papers/Fruehwald_2023_BNWT43F9.html",
    "title": "fasttrackpy",
    "section": "",
    "text": "CitationBibTeX citation:@software{fruehwald2023,\n  author = {Fruehwald, Josef and Barreda, Santiago},\n  title = {Fasttrackpy},\n  version = {v0.3.0},\n  date = {2023-11-28},\n  url = {https://fasttrackiverse.github.io/fasttrackpy/},\n  doi = {10.5281/ZENODO.10212099},\n  langid = {en},\n  abstract = {This is a python implementation of the FastTrack method.}\n}\nFor attribution, please cite this work as:\nFruehwald, Josef, and Santiago Barreda. 2023.\n“Fasttrackpy.” https://doi.org/10.5281/ZENODO.10212099."
  },
  {
    "objectID": "research/papers/Fruehwald_2023_MW4ESNC8.html",
    "href": "research/papers/Fruehwald_2023_MW4ESNC8.html",
    "title": "fave-recode",
    "section": "",
    "text": "Documentation: Docs\n\n\n\nCitationBibTeX citation:@software{fruehwald2023,\n  author = {Fruehwald, Josef},\n  title = {Fave-Recode},\n  version = {v0.2.0},\n  date = {2023-11-21},\n  url = {https://forced-alignment-and-vowel-extraction.github.io/fave-recode/},\n  doi = {10.5281/ZENODO.10392791},\n  langid = {en},\n  abstract = {The idea behind fave-recode is that no matter how much you\n    may adjust the dictionary of a forced-aligner, you may still want to\n    make programmatic changes to the output.}\n}\nFor attribution, please cite this work as:\nFruehwald, Josef. 2023. “Fave-Recode.” https://doi.org/10.5281/ZENODO.10392791."
  },
  {
    "objectID": "research/papers/Fruehwald_2024_5WSEQHGS.html",
    "href": "research/papers/Fruehwald_2024_5WSEQHGS.html",
    "title": "aligned-textgrid: Lightweight access to structured phonetic data",
    "section": "",
    "text": "CitationBibTeX citation:@inproceedings{fruehwald2024,\n  author = {Fruehwald, Josef and Brickhouse, Christian},\n  title = {Aligned-Textgrid: {Lightweight} Access to Structured Phonetic\n    Data},\n  booktitle = {Poster presented at SCiL 2024},\n  date = {2024-06-24},\n  url = {https://jofrhwld.github.io/scil_2024/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nFruehwald, Josef, and Christian Brickhouse. 2024.\n“Aligned-Textgrid: Lightweight Access to Structured Phonetic\nData.” In Poster Presented at SCiL 2024. https://jofrhwld.github.io/scil_2024/."
  },
  {
    "objectID": "research/papers/Labov_2013_QZP9CAP8.html",
    "href": "research/papers/Labov_2013_QZP9CAP8.html",
    "title": "One hundred years of sound change in Philadelphia: Linear Incrementaion, Reversal, and Reanalysis",
    "section": "",
    "text": "CitationBibTeX citation:@article{labov2013,\n  author = {Labov, William and Rosenfelder, Ingrid and Fruehwald, Josef},\n  title = {One Hundred Years of Sound Change in {Philadelphia:} {Linear}\n    {Incrementaion,} {Reversal,} and {Reanalysis}},\n  journal = {Language},\n  volume = {89},\n  number = {1},\n  pages = {30-65},\n  date = {2013},\n  url = {https://muse.jhu.edu/article/503024},\n  doi = {10.1353/lan.2013.0015},\n  langid = {en},\n  abstract = {The study of sound change in progress in Philadelphia has\n    been facilitated by the application of forced alignment and\n    automatic vowel measurement to a large corpus of neighborhood\n    studies, including 379 speakers with dates of birth from 1888 to\n    1991. Two of the sound changes active in the 1970s show a linear\n    pattern of incrementation in succeeding decades. The fronting of\n    back upgliding vowels /aw/ and /ow/ shows a reversal in the\n    direction of change, beginning with those born after 1940. The study\n    also finds a general withdrawal from two salient features of local\n    phonology, tense /æh/ and /oh/, led by those with higher education.\n    Younger speakers with higher education have also reorganized the\n    traditional Philadelphia tense/lax split of short-a to form a nasal\n    system with tensing before all and only nasal consonants. The\n    development of the Philadelphia vowel system can be understood in\n    the geographic context of neighboring dialects. Features in common\n    with North and North Midland dialects have accelerated in use while\n    features in common with South Midland and Southern dialects have\n    been reversed in favor of Northern patterns. The microevolution of a\n    linguistic system can be seen here as subject to phonological\n    generalizations but driven by social evaluation as features rise in\n    level of salience for members of the speech community.}\n}\nFor attribution, please cite this work as:\nLabov, William, Ingrid Rosenfelder, and Josef Fruehwald. 2013.\n“One Hundred Years of Sound Change in Philadelphia: Linear\nIncrementaion, Reversal, and Reanalysis.” Language 89\n(1): 30–65. https://doi.org/10.1353/lan.2013.0015."
  },
  {
    "objectID": "research/papers/Purse_2022_LIGPGR5R.html",
    "href": "research/papers/Purse_2022_LIGPGR5R.html",
    "title": "Frequency and morphological complexity in variation",
    "section": "",
    "text": "CitationBibTeX citation:@article{purse2022,\n  author = {Purse, Ruaridh and Fruehwald, Josef and Tamminga, Meredith},\n  title = {Frequency and Morphological Complexity in Variation},\n  journal = {Glossa: a journal of general linguistics},\n  volume = {7},\n  number = {1},\n  date = {2022-09-29},\n  url = {https://www.glossa-journal.org/article/id/5839/},\n  doi = {10.16995/glossa.5839},\n  langid = {en},\n  abstract = {Broad interest in probabilistic aspects of language has\n    reignited debates about a potential delineation between the shape of\n    an abstract grammar and patterns of language in use. A central topic\n    in this debate is the relationship between measures capturing\n    aspects of language use, such as word frequency, and patterns of\n    variation. While it has become common practice to attend to\n    frequency measures in studies of linguistic variation, fundamental\n    questions about exactly what linguistic unit’s frequency it is\n    appropriate to measure in each case, and what this implies about the\n    representations or processing mechanisms at play, remain\n    underexplored. In the present study, we compare how three frequency\n    measures account for variance in Coronal Stop Deletion (CSD) based\n    on large-scale corpus data from Philadelphia English: whole-word\n    frequency, stem frequency, and conditional (whole-word/stem)\n    frequency. While there is an effect of all three measures on CSD\n    outcomes in monomorphemes, the effect of conditional frequency is by\n    far the most robust. Furthermore, only conditional frequency has an\n    effect on CSD rates in -ed suffixed words. Thus, we suggest that\n    frequency effects in CSD are best interpreted in terms of\n    stem-conditional predictability of a suffix or word-edge. These\n    results lend support to the importance of asking these fundamental\n    questions about usage measures, and suggest that contemporary\n    approaches to frequency should take morphological complexity into\n    account.}\n}\nFor attribution, please cite this work as:\nPurse, Ruaridh, Josef Fruehwald, and Meredith Tamminga. 2022.\n“Frequency and Morphological Complexity in Variation.”\nGlossa: A Journal of General Linguistics 7 (1). https://doi.org/10.16995/glossa.5839."
  },
  {
    "objectID": "research/papers/Rosenfelder_2015_K57PJ2RE.html",
    "href": "research/papers/Rosenfelder_2015_K57PJ2RE.html",
    "title": "FAVE (Forced Alignment and Vowel Extraction) 1.2.2",
    "section": "",
    "text": "CitationBibTeX citation:@software{rosenfelder2015,\n  author = {Rosenfelder, Ingrid and Fruehwald, Josef and Evanini, Keelan\n    and Seyfarth, Scott and Gorman, Kyle and Prichard, Hilary and Yuan,\n    Jiahong},\n  title = {FAVE {(Forced} {Alignment} and {Vowel} {Extraction)} 1.2.2},\n  version = {v1.2.2},\n  date = {2015},\n  url = {http://dx.doi.org/10.5281/zenodo.9846},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nRosenfelder, Ingrid, Josef Fruehwald, Keelan Evanini, Scott Seyfarth,\nKyle Gorman, Hilary Prichard, and Jiahong Yuan. 2015. “FAVE\n(Forced Alignment and Vowel Extraction) 1.2.2.” http://dx.doi.org/10.5281/zenodo.9846."
  },
  {
    "objectID": "research/papers/Sneller_2019_8ERVHBSG.html",
    "href": "research/papers/Sneller_2019_8ERVHBSG.html",
    "title": "Using the Tolerance Principle to predict phonological change",
    "section": "",
    "text": "CitationBibTeX citation:@article{sneller2019,\n  author = {Sneller, Betsy and Fruehwald, Josef and Yang, Charles},\n  title = {Using the {Tolerance} {Principle} to Predict Phonological\n    Change},\n  journal = {Language Variation and Change},\n  volume = {31},\n  number = {1},\n  pages = {1-20},\n  date = {2019-03-02},\n  url = {https://www.cambridge.org/core/product/identifier/S0954394519000061/type/journal_article},\n  doi = {10.1017/S0954394519000061},\n  langid = {en},\n  abstract = {Language acquisition is a well-established avenue for\n    language change (Labov, 2007). Given the theoretical importance of\n    language acquisition to language change, it is all the more\n    important to formulate clear theories of transmission-based change.\n    In this paper, we provide a simulation method designed to test the\n    plausibility of different possible transmission-based changes, using\n    the Tolerance Principle (Yang, 2016) to determine precise points at\n    which different possible changes may become plausible for children\n    acquiring language. We apply this method to a case study of a\n    complex change currently in progress: the allophonic restructuring\n    of /æ/ in Philadelphia English. Using this model, we are able to\n    evaluate several competing explanations of the ongoing change and\n    determine that the allophonic restructuring of /æ/ in Philadelphia\n    English is mostly likely the result of children acquiring language\n    from mixed dialect input, consisting of approximately 40\\% input\n    from speakers with a nasal /æ/ split. We show that applying our\n    simulation to a phonological change allows us to make precise\n    quantitative predications about the progress of this change.\n    Moreover, it forces us to reassess intuitively plausible hypotheses\n    about language change, such as grammatical simplification, in a\n    quantitative and independently motivated framework of acquisition.}\n}\nFor attribution, please cite this work as:\nSneller, Betsy, Josef Fruehwald, and Charles Yang. 2019. “Using\nthe Tolerance Principle to Predict Phonological Change.”\nLanguage Variation and Change 31 (1): 1–20. https://doi.org/10.1017/S0954394519000061."
  },
  {
    "objectID": "research/papers/Wieling_2016_FU9RXCUV.html",
    "href": "research/papers/Wieling_2016_FU9RXCUV.html",
    "title": "Variation and Change in the Use of Hesitation Markers in Germanic Languages",
    "section": "",
    "text": "CitationBibTeX citation:@article{wieling2016,\n  author = {Wieling, Martijn and Grieve, Jack and Bouma, Gosse and\n    Fruehwald, Josef and Coleman, John and Liberman, M.},\n  title = {Variation and {Change} in the {Use} of {Hesitation} {Markers}\n    in {Germanic} {Languages}},\n  journal = {Language Dynamics and Change},\n  volume = {6},\n  number = {2},\n  pages = {199-234},\n  date = {2016},\n  url = {https://JoFrhwld.github.io/jofrhwld.github.io//research/papers/Wieling_2016_FU9RXCUV.html},\n  doi = {10.1163/22105832-00602001},\n  langid = {en},\n  abstract = {In this study, we investigate crosslinguistic patterns in\n    the alternation between um, a hesitation marker consisting of a\n    neutral vowel followed by a final labial nasal, and uh, a hesitation\n    marker consisting of a neutral vowel in an open syllable. Based on a\n    quantitative analysis of a range of spoken and written corpora, we\n    identify clear and consistent patterns of change in the use of these\n    forms in various Germanic languages (English, Dutch, German,\n    Norwegian, Danish, Faroese) and dialects (American English, British\n    English), with the use of um increasing over time relative to the\n    use of uh. We also find that this pattern of change is generally led\n    by women and more educated speakers. Finally, we propose a series of\n    possible explanations for this surprising change in hesitation\n    marker usage that is currently taking place across Germanic\n    languages.}\n}\nFor attribution, please cite this work as:\nWieling, Martijn, Jack Grieve, Gosse Bouma, Josef Fruehwald, John\nColeman, and M. Liberman. 2016. “Variation and Change in the Use\nof Hesitation Markers in Germanic Languages.” Language\nDynamics and Change 6 (2): 199–234. https://doi.org/10.1163/22105832-00602001."
  },
  {
    "objectID": "software/packages/aligned-textgrid.html",
    "href": "software/packages/aligned-textgrid.html",
    "title": "aligned-textgrid",
    "section": "",
    "text": "CitationBibTeX citation:@software{fruehwald2023,\n  author = {Fruehwald, Josef and Brickhouse, Christian},\n  title = {Aligned-Textgrid},\n  version = {v0.5.0},\n  date = {2023-11-22},\n  url = {https://forced-alignment-and-vowel-extraction.github.io/alignedTextGrid/},\n  doi = {10.5281/zenodo.10190692},\n  langid = {en},\n  abstract = {The aligned-textgrid package provides a python interface\n    for representing and operating on TextGrids produced by forced\n    aligners like FAVE or the Montreal Forced Aligner. Classes provided\n    by aligned-textgrid represent hierarchical and precedence\n    relationships among data stored in TextGrid formats allowing for\n    simplified and more accessible analysis of aligned speech data.}\n}\nFor attribution, please cite this work as:\nFruehwald, Josef, and Christian Brickhouse. 2023.\n“Aligned-Textgrid.” https://doi.org/10.5281/zenodo.10190692."
  },
  {
    "objectID": "software/packages/fasttrackpy.html",
    "href": "software/packages/fasttrackpy.html",
    "title": "fasttrackpy",
    "section": "",
    "text": "CitationBibTeX citation:@software{fruehwald2023,\n  author = {Fruehwald, Josef and Barreda, Santiago},\n  title = {Fasttrackpy},\n  version = {v0.3.0},\n  date = {2023-11-28},\n  url = {https://fasttrackiverse.github.io/fasttrackpy/},\n  doi = {10.5281/ZENODO.10212099},\n  langid = {en},\n  abstract = {This is a python implementation of the FastTrack method.}\n}\nFor attribution, please cite this work as:\nFruehwald, Josef, and Santiago Barreda. 2023.\n“Fasttrackpy.” https://doi.org/10.5281/ZENODO.10212099."
  },
  {
    "objectID": "software/packages/syllabifyr.html",
    "href": "software/packages/syllabifyr.html",
    "title": "syllabifyr: Syllabifier for CMU Dictionary Transcriptions",
    "section": "",
    "text": "CitationBibTeX citation:@software{fruehwald2020,\n  author = {Fruehwald, Josef},\n  title = {Syllabifyr: {Syllabifier} for {CMU} {Dictionary}\n    {Transcriptions}},\n  version = {v0.1.1},\n  date = {2020-10-24},\n  url = {https://jofrhwld.github.io/syllabifyr/},\n  doi = {10.5281/zenodo.10393038},\n  langid = {en},\n  abstract = {The goal of `syllabifyr` is to provide tidy\n    syllabification of phonetic transcriptions. So far, only CMU dict\n    transcriptions are supported.}\n}\nFor attribution, please cite this work as:\nFruehwald, Josef. 2020. “Syllabifyr: Syllabifier for CMU\nDictionary Transcriptions.” https://doi.org/10.5281/zenodo.10393038."
  },
  {
    "objectID": "teaching/courses/2017_lsa/lectures/Session_1.nb.html",
    "href": "teaching/courses/2017_lsa/lectures/Session_1.nb.html",
    "title": "Introduction to R",
    "section": "",
    "text": "Welcome to Statistical Modelling with R. If there is one thing to remember from this course, it is that your analysis workflow should look something like this:",
    "crumbs": [
      "LSA 2017 Course",
      "Lectures",
      "Introduction to R"
    ]
  },
  {
    "objectID": "teaching/courses/2017_lsa/lectures/Session_1.nb.html#hellos",
    "href": "teaching/courses/2017_lsa/lectures/Session_1.nb.html#hellos",
    "title": "Introduction to R",
    "section": "",
    "text": "Welcome to Statistical Modelling with R. If there is one thing to remember from this course, it is that your analysis workflow should look something like this:",
    "crumbs": [
      "LSA 2017 Course",
      "Lectures",
      "Introduction to R"
    ]
  },
  {
    "objectID": "teaching/courses/2017_lsa/lectures/Session_1.nb.html#the-process-of-learning-r-and-modelling",
    "href": "teaching/courses/2017_lsa/lectures/Session_1.nb.html#the-process-of-learning-r-and-modelling",
    "title": "Introduction to R",
    "section": "The process of learning R and Modelling",
    "text": "The process of learning R and Modelling\nThese are some of the core areas I figure are necessary to getting good at statistical modelling in R:\n\nUsing R (and RStudio) well\nFeeling comfortable and fluid reorganizing and summarizing data\nVisualizing Data\nDeciding before you model what you want to compare to what\nHow to translate your analysis goals into R code\nUnderstanding a little bit about statistics\nWhen something goes wrong, being able to accurately attribute your difficulty to one of the above topics\n\nThese are all skills you can achieve through practice, experience, and occasional guidance from someone more skilled than you. It is exactly like acquiring any other skill or craft. At first it will be confusing, you’ll make some mistakes, and it won’t look so good. I think\n\n\n\n\n\n\n\n\n\nThe first hat I ever knit\n\n\n\n\n \n\n\n\n\n\nThe most recent hat I knit\n\n\n\n\n\nThe way I improved my knitting is exactly the same as how you can improve your R programming ability:\n\nI knit a lot (almost every day).\nI memorized a bunch of stuff.\nRemembered where to look up the stuff I don’t have memorized.\nMy knitting became more “idiomatic” (i.e. I started knitting like how other knitters knit).\nI learned how to identify and fix mistakes without undoing my entire project.\nI developed good workspace hygiene & organization.\nAs I got the basics down, I started researching and incorporating fussy little details into my work.\n\nMost of the content of the course is devoted to core R programming (things you should be memorizing or remembering where to find help), but I’ll try my best to annotate portions of the notes which correspond to workspace hygiene, being idiomatic, etc, so that you can distinguish between them.",
    "crumbs": [
      "LSA 2017 Course",
      "Lectures",
      "Introduction to R"
    ]
  },
  {
    "objectID": "teaching/courses/2017_lsa/lectures/Session_1.nb.html#course-outline",
    "href": "teaching/courses/2017_lsa/lectures/Session_1.nb.html#course-outline",
    "title": "Introduction to R",
    "section": "Course Outline",
    "text": "Course Outline\nThe course will follow the workflow outlined at the beginning: begin → summarize → visualize → analyze.\n\n\n\n\n\n\n\n\nWeek\nMonday\nThursday\n\n\n\n\n1\n–\nIntro - Basics & R Notebooks\n\n\n2\nData Frames & Factors\nSplit-Apply-Combine, Reshaping\n\n\n3\nggplot2\nFitting Linear Models\n\n\n4\nmap functions & fitting many models\nMixed Effects Linear models\n\n\n5\nBootstraps & Visualization\n–\n\n\n\n\n\n\n\n\n\nWorkspace Hygiene\n\n\n\nRecommended Course Directory Structure\nIf you have a directory planning structure that you’re happy with, go ahead and do that. But if how to organize your R analysis life is something you’d like to get out of this course, I’d recommend the following directory structure & naming conventions.\n├── lsa_2017\n│   └── r_modelling*\n│       ├── assignments\n│       ├── data\n│       └── lectures\n        \nThe r_modelling directory will be the home directory for the course. I would recommend creating a new R Notebook for each lecture (more on that in a moment) and giving them a naming convention like:\n01_lecture.Rmd\n02_lecture.Rmd\nRight now eliminate the impulse to create any folders or file names with spaces in them.",
    "crumbs": [
      "LSA 2017 Course",
      "Lectures",
      "Introduction to R"
    ]
  },
  {
    "objectID": "teaching/courses/2017_lsa/lectures/Session_1.nb.html#r-rstudio-and-r-notebooks",
    "href": "teaching/courses/2017_lsa/lectures/Session_1.nb.html#r-rstudio-and-r-notebooks",
    "title": "Introduction to R",
    "section": "R, RStudio and R Notebooks",
    "text": "R, RStudio and R Notebooks\nWe’re going to be using R, RStudio, and R Notebooks in this course, and it’s a little important to keep straight what these three things are:\n\nR\nR is a programming language that runs on your computer. At its barest bones, it looks like this:\n\n\n\n\n\nYou can type text into the prompt there, and if you’ve successfully memorized the right R commands, it’ll do some things.\n\n\nRStudio\nRStudio is like an Instagram filter over to of R, to make your R use experience better. It visually organizes some important components of using R into panes, and offers code completion suggestions. For example, if you ember there’s something called a “Wilcoxon test”, but you don’t remember what the function in R is, you can start typing in Wilc, and this will happen:\n\n\n\n\n\nRStudio’s autocompletion is really useful for a lot of other things, like reminding you what the column names are in your data frame, what the names of all the arguments to a function are, etc.\nBut perhaps the most valuable component in R Studio these days is its authoring tools, like R Notebooks\n\n\nR Notebooks\nR Notebooks allow you to document your code in plain text, insert R Code chunks, and view the results of the R code all in one place, then compile it into a nice looking notebook.\n\n\n\n\n\n\n~5 Minute Activity\n\n\n\n\nGoals\n\nStart a new RStudio Project.\nCreate a new R Notebook.\nRun some code in the R Notebook.\nPreview the R Notebook in HTML\n\n\n\nStart a new RStudio Project\nCreate a new RStudio Project, either by using the menu options File &gt; New Project or by clicking on the  icon in the top right corner of the RStudio window. If you have created directory structure above choose Existing Directory and choose r_modelling. Otherwise, select the options New Directory then Empty Project and tell it the project name is r_modelling\n\n\nCreate a new R Notebook\nOpen a new R Notebook using the menu command File &gt; New File &gt; R Notebook. If this is the first time you’ve opened an R Notebook on your computer, you’ll probably be faced with the following prompt:\n\n\n\nClick “Yes”, and wait for the installation to finish. A window with a bunch of gobbledygook will pop up, and that’s fine. Once it’s all finished, the new file should open.\n\n\nRun some code in the R Notebook\nFirst, run the R code chunk that comes automatically in a new R Notebook by clicking on the green “play” button in the top right corner of the code chunk.\nNext, insert a new R code chunk at the bottom of the notebook (directions for how to do so are already included in the new R Notebook), and inside, enter:\n\"Hello World\"\nThen run this code chunk by clicking the play button.\n\n\nPreview the R Notebook in HTML\nClick the “Preview” button at the top of the R Notebook panel to compile it into an HTML document. You will need to save the notebook first. In the lectures folder, save it as 00_practice.Rmd\n\n\n\n\n\nDiscussion\nI’m going to recommend (for now at least) that you run all of your code though an R Notebook. It is possible to just type things into the R console, but that’s kind of like dictating a paper into thin air. Once you’ve spoken the words, they disappear and can be hard to recover.\nMy earlier advice would have been to write all of your code in an R script file, but that also separates the code from its results, which can be hard for beginners to keep track of.",
    "crumbs": [
      "LSA 2017 Course",
      "Lectures",
      "Introduction to R"
    ]
  },
  {
    "objectID": "teaching/courses/2017_lsa/lectures/Session_1.nb.html#installing-r-packages",
    "href": "teaching/courses/2017_lsa/lectures/Session_1.nb.html#installing-r-packages",
    "title": "Introduction to R",
    "section": "Installing R Packages",
    "text": "Installing R Packages\nR comes with a lot of functionality installed, but one way that R is extensible is through users’ ability to contribute new code & data through it’s package management system. We’re going to using a number of these packages in the course, especially since a few of them have fundamentally changed the way R programming works in the past 3 years. There’s also a course R package I’ve created to easily distribute sample datasets.\nHere’s a basic diagram of how R packages work:\n\n\n\n\n\n\nInstalling Packages\n\ninstall.packages()\nMost R packages are distributed through CRAN (Comprehensive R Archive Network). When you run function install.packages(\"x\"), R checks whether the package \"x\" exists on CRAN, and installs it on your computer if it does. You maybe asked to choose a “CRAN mirror” the first time you run install.packages(). This is because there are many copies of CRAN distributed across the internet. I’d recommend choosing the first option called 0-Cloud.\n\n\ninstall_github()\nAs a package developer, getting a package onto CRAN can be a bit of a pain, so some packages (and development versions of many) are also available on GitHub, which can be easily installed with devtools::install_github(\"username/package\").\n\n\n\nInstalling packages is different from loading packages\nInstalling a package is different from loading packages. Installing a package only downloads and configures the code on your computer. In order to use the contents of a package, you need to load it into your R session with library().\n\nYou only need to run install.packages() once to install a package, or to update a package.\nYou need to run library() at the start of every new R session in order to use the functionality from that package.\n\nFor example, ggplot() is a function from the package ggplot2. I have already installed ggplot2 on my computer, but if I try to use ggplot() before loading the package with library(), I’ll get the error that the function was not found.\n\n\nr\n\nfoo &lt;- ggplot()\n\nError in ggplot(): could not find function \"ggplot\"\n\n\n\n\nr\n\nlibrary(\"ggplot2\")\n\nError in library(\"ggplot2\"): there is no package called 'ggplot2'\n\n\nr\n\nfoo &lt;- ggplot()\n\nError in ggplot(): could not find function \"ggplot\"\n\n\n\n\n\n\n\n\n~2 minute activity\n\n\n\nLet’s install all of the packages we’re going to use in the course. Double check that you’re connected to the internet.\nCreate a notebook for this lecture called 01_lecture.Rmd. Copy-paste the following into an R code chunk and run it:\n\n\nr\n\ninstall.packages(\n  c(\"tidyverse\",\n    \"devtools\")\n)\n\nlibrary(\"devtools\")\n\ninstall_github(\"jofrhwld/lsa2017\")",
    "crumbs": [
      "LSA 2017 Course",
      "Lectures",
      "Introduction to R"
    ]
  },
  {
    "objectID": "teaching/courses/2017_lsa/lectures/Session_1.nb.html#r-basics",
    "href": "teaching/courses/2017_lsa/lectures/Session_1.nb.html#r-basics",
    "title": "Introduction to R",
    "section": "R Basics",
    "text": "R Basics\nWe’re now going to run through some very basics of R, specifically:\n\nBasic Data Types\nBasic Calculations\nAssignment\nVectors\nIndexing\n\nCreate a new R Notebook. Change the Title field to Intro to R, and save it as 0_lecture.Rmd in the folder lectures.\nAs we come to a code chunk in the lecture, either copy-paste or re-type it into a new code chunk in your lecture R notebook, and run it.\n\nBasic Calculations\nOne way to think of R is as an overblown calculator.\n\n\nr\n\n3+3 \n\n[1] 6\n\n\nr\n\n2*4\n\n[1] 8\n\n\nr\n\n(369-1)/6\n\n[1] 61.33333\n\n\nBut it’s not all that useful to do a bunch of calculations without saving the results for later, which is where assignment comes in.\n\n\nAssignment\nYou can assign values to variables using the assignment operator: &lt;- or -&gt; (but in practice, only use &lt;-).\n\nvariable &lt;- value\n\n\n\nr\n\nx &lt;- 10\ny &lt;- 2*3\n\nOnce you’ve assigned a value to a variable, you can reuse the value stored in that variable for other purposes, like just printing it out again\n\n\nr\n\nx\n\n[1] 10\n\n\nr\n\ny\n\n[1] 6\n\n\nOr adding the two values together\n\n\nr\n\nx + y \n\n[1] 16\n\n\nIn short, you can use these variables x and y like they are the values you assigned to them. If this is your first time programming, here are a few things to clarify:\nNote\n\nx and y didn’t exist before you created them by assigning values to them.\nYou could have chosen almost any name for these variables.\nYou can just as easily assign new values to these variables.\n\n\n\n\n\n\n\nNaming Things\n\n\n\nx and y are lousy names for variables. When it comes to naming variables, there’s a famous saying:\n\n“There are only two hard things in Computer Science: cache invalidation and naming things.” — Phil Karlton\n\nFor best practices on naming variables, I’ll refer you to the tidyverse style guide by Hadley Wickham. To briefly summarize it:\n\nUse only lowercase letters and numbers.\nUse _ to separate words in a a variable name.\nYou’re actually not able to start a variable name with a number.\n\nAlso, be guided by The Principle of Least Effort. Use the minimal amount of characters that are still clearly interpretable.\n# Good Names\nmodel_1\nmodel_full\n\n\n# Bad Names\nthe_first_model_I_ever_fit\njust_trying_out_a_model_with_all_predictors\nm_01\nm_agdf\nAlso, just use good judgment. There is nothing in R preventing you from doing stuff like this to yourself.\n\n\nr\n\nfive &lt;- 10\nten &lt;- 5\n\nyellow &lt;- \"green\"\n\n\n\nAnother thing to keep in mind is that R can’t handle any other characters in numeric values other than 0 through 9 and decimal places. All of these will fail:\n\n\nr\n\n# no commas\nthousand &lt;- 1,000\n\nError: &lt;text&gt;:2:14: unexpected ','\n1: # no commas\n2: thousand &lt;- 1,\n                ^\n\n\n\n\nr\n\n# no spaces\nthousand &lt;- 1 000\n\nError: &lt;text&gt;:2:15: unexpected numeric constant\n1: # no spaces\n2: thousand &lt;- 1 000\n                 ^\n\n\n\n\nr\n\n# like this\nthousand &lt;- 1000\n\n\n\nr\n\n# no currencies\ndollars &lt;- $1000\n\nError: &lt;text&gt;:2:12: unexpected '$'\n1: # no currencies\n2: dollars &lt;- $\n              ^\n\n\n\n\nr\n\n# no percentages\n\npercent &lt;- 51%\n\nError: &lt;text&gt;:3:14: unexpected input\n2: \n3: percent &lt;- 51%\n                ^\n\n\n\nAdditional data types\nIn addition to numbers, other basic data types in R are character and logical.\n\n\nr\n\n# character data\ndigital_words &lt;- c(\"fam\",\n                   \"Harambe\",\n                   \"tweetstorm\",\n                   \"@\")\n\n\n\nr\n\n# logical values\nTRUE\n\n[1] TRUE\n\n\nr\n\n# a logical test\n(10/2) &lt; 3\n\n[1] FALSE\n\n\n\n\nOn using quotes\nWhen you enter characters without quotes around them, R assumes you’re referring to a variable. If you tried to do the assignment above without the quotes, you’ll get an error.\n\n\nr\n\ndigital_words_fail &lt;- c(fam,\n                        Harambe,\n                        tweetstorm)\n\nError in eval(expr, envir, enclos): object 'fam' not found\n\n\nHere, R saw fam, which isn’t in quotes, searched the environment for any variables named fam and couldn’t find any.\nWhen you put characters in quotes, R assumes it’s a character value, even if there’s a variable by the same name.\n\n\nr\n\ndigital_words\n\n[1] \"fam\"        \"Harambe\"    \"tweetstorm\" \"@\"         \n\n\nr\n\n\"digital_words\"\n\n[1] \"digital_words\"\n\n\n\n\n\nVectors\nVectors are essentially lists of data, and can contain characters, numbers, or TRUE FALSE values. There are a number of ways to create vectors in R, and frequently doing data manipulation will produce subvectors of data.\n\n1:10\n\nThis produces a vector of integers from 1 to 10. Reversing the order of the numbers will produce a vector of decreasing values.\n\nc(...)\n\nThis produces a vector of whatever is passed as an argument to c().\n\nc(1,2,3,4)\n\n\nseq(from,to,...)\n\nThis produces a sequence of numbers either by a given increment or evenly spaced to a given length.\n\nseq(1,10,by=0.5)\nseq(1,10,length=11)\n\n\nrep(x,...)\n\nThis produces a vector of repetitions of x by a given number of times.\n\nrep(1,6)\nrep(1:3,2)\nrep(\"hello world\",4)\n\n\n\n\nVector Arithmetic\n\nVector and A Number\nA pretty cool and unique feature of R is how you can do arithmetic with vectors. For example, let’s say you’ve interviewed a bunch of speakers of the following ages\n\n\nr\n\nages &lt;- c(18, 35, 41, 62)\n\nIf you wanted to know the year of birth of these speakers, it’s as easy as:\n\n\nr\n\n2017 - ages\n\n[1] 1999 1982 1976 1955\n\n\nR has taken each value in ages, and subtracted it from 2017, and created a new vector with the results.\nOr, if you wanted to know in which year these speakers turned 17, it’s as easy as:\n\n\nr\n\n(2017 - ages) + 17\n\n[1] 2016 1999 1993 1972\n\n\n\n\nVector and a Vector\nOr, let’s say these speakers weren’t all interviewed the same year. Half were interviewed in the 90s, and half in the 2000s.\n\n\nr\n\ninterview_year &lt;- c(1995, 1996, 2003, 2004)\n\nGetting each speaker’s date of birth is as simple as:\n\n\nr\n\ninterview_year - ages\n\n[1] 1977 1961 1962 1942\n\n\nThis worked because the two vectors, interview_year and ages were the same length. R took the first values of age and subtracted it from the first value of interview_year, the second value of age and subtracted it from the second value of interview_year, etc, creating new vector of the result. You could easily assign this output to a new variable.\n\n\nr\n\ndob &lt;- interview_year - ages\n\nOf course, if you now wanted to know what year these speakers turned 17, you could do it like so:\n\n\nr\n\n(interview_year - ages) + 17\n\n[1] 1994 1978 1979 1959\n\n\n\n\n\n\n\n\n~5 minute activity\n\n\n\nA Starbucks Grande filter coffee in the UK currently costs £1.85. The value of £1 before the Brexit vote was about $1.49. After the vote, it dropped down to about $1.31, and lately it’s been closer to $1.27.\nUsing vector arithmetic as much as possible, find out how the value in dollars of my coffee has changed.\n\n\n\n\n\n\nIndexing\nIf you have a bunch of values stored in a vector, and you want to pull out specific ones, you can do so by indexing it with square brackets [].\n\nIndexing by Position\nLet’s start by indexing by position.\n\nvector[position]\n\nR has some built in vectors for you to use, like one called letters. We haven’t defined letters, and it’s not listed as being in your R environment, but it’s there.\n\n\nr\n\nletters\n\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n[20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\n\n\nThe first value in a vector has index 1, the second index 2, and so on. If you’ve forgotten what the 19th letter of the alphabet is, you can find it out like so:\n\n\nr\n\nletters[19]\n\n[1] \"s\"\n\n\nIf instead of just one number, you use another vector to index letters, you’ll get back out another vector.\n\n\nr\n\nyes &lt;- c(25, 5, 19)\nletters[yes]\n\n[1] \"y\" \"e\" \"s\"\n\n\nr\n\nabba &lt;- c(1, 2, 2, 1)\nletters[abba]\n\n[1] \"a\" \"b\" \"b\" \"a\"\n\n\n\n\nLogical Indexing\nYou can also index by logical values.\n\nvector[true false vector]\n\nLet’s come back to our vector of speaker’s ages\n\n\nr\n\nages\n\n[1] 18 35 41 62\n\n\nIf we make another vector of TRUE and FALSE values of the same length, we can use it to index test_vec.\n\n\nr\n\nlogical_vec &lt;- c(T, F, T, F)\nages[logical_vec]\n\n[1] 18 41\n\n\nYou only get back values where the index vector was TRUE.\nOf course, what you’ll usually do is generate a vector of TRUE and FALSE values by using a logical operator.\n\n\nr\n\nages &gt; 40\n\n[1] FALSE FALSE  TRUE  TRUE\n\n\nr\n\nages[ages &gt; 40]\n\n[1] 41 62\n\n\n\n\n\n\n\n\n~2 minute activity\n\n\n\nLet’s assume our speakers had the following names:\n\n\nr\n\nspeaker_names &lt;- c(\"Charlie\", \"Skyler\", \"Sawyer\", \"Jamie\")\n\nUsing logical indexing and the ages in ages and year of interview in interview_year (or just dob, if you assigned anything to that variable), find out which speakers were born after 1960.\n\n\n\n\n\nLogical Operators\nThe following operators will return a vector of TRUE and FALSE values.\n\n\n\nOperator\nMeaning\n\n\n\n\n==\nexactly equal to\n\n\n!=\nnot equal to\n\n\n&gt;\ngreater than\n\n\n&lt;\nless than\n\n\n&gt;=\ngreater than or equal to\n\n\n&lt;\nless than\n\n\n&lt;=\nless than or equal to\n\n\n\nYou can use these to compare vectors to single values, as we’ve seen, but you can also compare vectors to vectors if they are the same length. Comparison is done elementwise.\n\n\nr\n\ngroup_a &lt;- c(20, 10, 13, 60)\ngroup_b &lt;- c(11, 31,  2,  9)\n\ngroup_a &lt; group_b\n\n[1] FALSE  TRUE FALSE FALSE\n\n\nThere are three more operators that have an effect on TRUE and FALSE vectors.\n\n\n\nOperator\nMeaning\n\n\n\n\n!\nnot x  changes all T to F and F to T\n\n\n|\nx or y\n\n\n&\nx and y\n\n\n\n\n\nr\n\nx &lt;- c(T, T, F, F)\ny &lt;- c(T, F, T, F)\n\n\n\nr\n\ncbind(\n  x = x,\n  y = y,\n  and = x&y, \n  or = x|y\n)\n\n         x     y   and    or\n[1,]  TRUE  TRUE  TRUE  TRUE\n[2,]  TRUE FALSE FALSE  TRUE\n[3,] FALSE  TRUE FALSE  TRUE\n[4,] FALSE FALSE FALSE FALSE\n\n\n\n\n%in%\nThis gets its own heading because it’s so useful, and you’ll use it a lot. If you say a %in% b, R checks every value in a to see if it’s in b.\n\nvalue %in% vector\n\n\n\nr\n\n# Was Sage in our study?\n\n\"Sage\" %in% speaker_names\n\n[1] FALSE\n\n\n\n\nr\n\n# Was Schuyler in our study?\n\n\"Schuyler\" %in% speaker_names\n\n[1] FALSE\n\n\nr\n\n# Yes, but not spelled that way.\n\n\"Skyler\" %in% speaker_names\n\n[1] TRUE\n\n\nThe first item can also be a vector.\n\n\nr\n\n# How about all of these people?\n\ncheck_names &lt;- c(\"Oakley\", \"Charlie\", \"Azaria\", \"Landry\", \"Skyler\", \"Justice\")\ncheck_names %in% speaker_names\n\n[1] FALSE  TRUE FALSE FALSE  TRUE FALSE\n\n\nr\n\ncheck_names[check_names %in% speaker_names]\n\n[1] \"Charlie\" \"Skyler\" \n\n\nr\n\ncheck_names[!(check_names %in% speaker_names)]\n\n[1] \"Oakley\"  \"Azaria\"  \"Landry\"  \"Justice\"",
    "crumbs": [
      "LSA 2017 Course",
      "Lectures",
      "Introduction to R"
    ]
  },
  {
    "objectID": "teaching/index.html",
    "href": "teaching/index.html",
    "title": "Teaching",
    "section": "",
    "text": "Summer 2017 R Course at LSA Summer Institute\nFall 2022 NLP Course\nSpring 2023 Statistics for linguistics\nSpring 2023 Quantitative Investigations in the Social Sciences"
  },
  {
    "objectID": "teaching/index.html#select-courses",
    "href": "teaching/index.html#select-courses",
    "title": "Teaching",
    "section": "",
    "text": "Summer 2017 R Course at LSA Summer Institute\nFall 2022 NLP Course\nSpring 2023 Statistics for linguistics\nSpring 2023 Quantitative Investigations in the Social Sciences"
  }
]